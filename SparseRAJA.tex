
\chapter{Sparse Transformations}
\begin{abstract}
Performance portability libraries like RAJA and Kokkos are a growing approach to the maintainability problems of large applications. 
While these libraries can productively represent and efficiently execute many computations, they lack robust support for an important type: sparse computations. 
While it is technically possible to implement some sparse computations in RAJA, users cannot write sparse codes in a way that respects the abstractions provided by RAJA to think about and program the problem.
Furthermore, changing the format of the sparse data becomes a porting task that touches every part of the code. 
Rather than relying on existing approaches to sparse computations, which use domain-specific languages and compilers to generate efficient implementations, my approach incorporates the necessary abstractions into the RAJA library itself. 
RAJA already contains a strong separation of the components of a computation: the operation, data, iteration space, and schedule. 
The key idea of my approach is to treat the sparsity as its own component in the RAJA program. 

The challenges of this approach lie in achieving good performance without losing portability. 
Two emerge specifically: constructing / traversing a sparse iteration space and accessing data without using searches. 
For the problem of the iteration space and schedule, I propose using leader and follower iterators to represent and traverse sparse iteration spaces, built on the symbolic iteration space capabilites I developed to support triangular iteration spaces. 
This approach supports coordinate storage, and can easily be extended to support compressed row and column storage formats. 
Efficient iteration would work as long as the order of the data matches the schedule, and can support different formats without changing the schedule. 
\end{abstract}

%Introduce sparse computations, existing approaches, and the constraints of the problem i'm solving
\section{Introduction}

Sparse computations have long been a bottleneck for high performance computing applications. 

Sparse computations are so troublesome because of the wide variety of formats used, all encoding different important data characteristics.

There have been many approaches to reduce the impact of this variety: general sparse formats, standardized libraries, and sparse compilation.

General sparse formats are good, but fail to leverage the data characteristics of specialized formats.

Standardized libraries make writing some codes easy, but only when they use the formats and functions provided by the library.

Compilation approaches make writing code easy, and offer good performance, but support a limited range of computations and introduce build system complexities and fragilities.
Also, there is the cost of switching code to use that compiler's language instead of the one its already written in.

Each of these options suffers in either performance, productivity, or portability.
Performance portability libraries like RAJA strike a great balance here, but offer little support for sparse computations.
Many of the abstractions that a programmer would use to think about a computation, like multi-dimensional data and nested loops, do not transfer to the domain of sparse computation.

My approach explores the possibilities of incorporating some of the advances in sparse computations developed in previous compiler approaches into a performance portability library.

My approach builds on the strong separation of concerns present in the RAJA library, taking it a step further by treating the sparsity of the data as its own component.
By isolating the sparsity as its own concern, it becomes more straightforward to specify its structure, as well as how it interacts with the other components of a RAJA computation.

One of the central challenges to this approach is the lack of code generation capabilities present in the compiler approaches.

I make the following contributions:
\begin{itemize}
\item An interface for format-agnostic representation of sparse computations in the RAJA performance portability library.
\item An approach for the partial automation of the construction of a sparse iteration space.
\item An approach for efficient access of sparse data without requiring the code generation capabilities of compiler-based approaches
\item A prototype implementation of these components for two classes of sparse formats
\end{itemize}

\section{Design Considerations}

\section{Constructing a Sparse Iteration Space}

Omitting unnecessary iterations is key to the performance of a sparse computation. 


The first performance barrier for SparseRAJA is the representation and construction of the sparse iteration space.
While individual dimensions in a RAJA iteration space can be ranges (using \verb.RangeSegment.) or arbitrary lists (using \verb.ListSegment.), dimensions can only be combined using the cartesian product. 
This presents a problem, as scarcely any sparse iteration spaces can be represented as a cartesian product.
Another option is needed, and here, I explore two.

\subsection{Option 1: Leader/Follower Iterators}

The leader/follower iterator approach requires no changes to the kernel policy, but is limited in the scheduling orders in can support. 
At a high level, the iterators for each loop dimension are synchronized, traversing a zipped list rather than a cartesian product. 
Because this method incorporates the synchronization through the segments themselves, it does introduce some runtime overhead.

When constructing the sparse iteration space, the outermost segment is created as a \verb.LeaderSegment. object and the inner segments are created as \verb.FollowerSegment. objects.
The inner \verb.FollowerSegment. objects store a reference to the lead segment with which they will synchronize.
Using this reference, the follower segments instantiate inner loops of length one, containing only the value in the synchronized position. 
This has the effect of compressing the multi-dimensional loop nest into a 1 dimensional loop nest traversing all the dimensions together.

Note that in this form, the approach can only support perfectly nesting schedules.
This becomes clear with an example.
Consider the following code, which accumulates the row sums of a sparse matrix into the dense vector \verb.y..:
\begin{lstlisting}
using POLICY=KernelPolicy<
  statement::For<0,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>
    >
  >
>;

auto init_lam = [=](auto i) {
  y(i) = 0.0;
}
auto accum_lam = [=](auto i, auto j) {
  y(i) += A(i,j);
}

auto i_dim = LeaderSegment(  {0,0,1,2,4,4,4,7});
auto j_dim = FollowerSegment({1,8,0,2,3,4,7,9});

kernel<POLICY>(make_tuple(i_dim,j_dim), init_lam, accum_lam);
\end{lstlisting}
The correct behavior of this loop would be to zero out \verb.y(0)., then add to it \verb.A(0,1). and \verb.A(0,8)..
Next, it would zero out \verb.y(1). and add to it \verb.A(1,0)..
This process should continue, summing one value into \verb.y(2)., three values into \verb.y(4)., and finally one value into \verb.y(7)..

However, using this version of the leader/follower formulation, a different behavior emerges.
Because all iterator incrementing happens in the leader segment's loop level, the contents of \verb.y. are zeroed each time.
\verb.y(0). is zeroed, then \verb.A(0,1). is added.
Then \verb.y(0). is zeroed and \verb.A(0,8). is added.
This repeats with each point in the iteration space, constantly overwriting the output.

A small refinement to the leader/follower iterator approach solves two problems at once: supporting imperfectly nested loops and laying the foundation for supporting compressed dimensions.
Rather than doing all incrementing within the leader iterator and having the follower iterators traverse a length one segment, the task is split so the follower iterators increment a collective index value as long as the segment above them holds the same value.

\subsection{Option 2: Loop Flattening}

The second option, loop flattening, approaches the problem from the direction of the kernel policy rather than the iteration space objects themselves.
Here, a new policy statement type is introduced: \verb.FlatFor.. 
It functions similarly to the \verb.For. statement policy, but rather than iteration a single segment, it iterates multiple simultaneously. 

Because this approach changes the kernel policy, a template parameter, it is less amenable to runtime modifications. 
Furthermore, it more strictly encodes the data layout into the schedule, making it more costly to change the computation to use a different format.
However, it would incur less overhead during kernel execution than the Leader/Follower Iterators approach, as it avoids the code associated with traversing the length one inner loop nests.

An additional drawback of this approach is that it only supports perfect nesting for the dimensions that it flattens. 
This means that a loop nest that uses additional statements to initialize data or write temporaries back to memory either before or after the second nesting level cannot be represented using the \verb.FlatFor. approach.
Because of these drawbacks, I use the leader/follower iterator approach in the prototype, but an approach that combines the two may be the most effective.


\section{Traversing Sparse Data Efficiently}

Even with the iteration space reduced to only the necessary points, acceptable performance depends on traversing the sparse data structures efficiently without requiring a search on each access.
Here, the tradeoff is between flexibility in supporting types of computations and the performance benefits of more aggressive specialization.

\subsection{Option 1: ``Expected Next Access'' Cache}

The most flexible approach is something akin to software prefetching, based on the assumption that data will be accessed in order. 
With this approach, before an access reverts to a search of the sparse data, it checks if the current access is for the next nonzero in the View.
If so, it skips the search and immediately returns the value.
If not, it searches the View for the desired value.

While this approach incurs the cost of checking the access against the expected, it avoids the much more expensive cost of searching the entire data structure each time teh View is read or written.
Additionally, it only needs a snigle access function, avoiding the type manipulation of the other options, and supports correct execution for all kernels, regardless of data access patterns.
Listing~\ref{expectedAccessImpl} shows a possible implementation of such an access function.
\begin{figure}
\begin{lstlisting}[caption={Possible implementation fo the Expected Next Access approach to efficient data traversal.},label=expectedAccessImpl]
ElementType access(auto i0, auto i1) {
  static int expectedIdx = 0;
  if (i0 == dims[0][expectedIdx] && i1 == dims[1][expectedIdx]) {
    return values[expectedIdx++];
  }
  
  entryIndex = search(i0,i1);
  if (entryIndex == -1) {
    return 0;
  } else {
    expectedIdx = entryIndex+1;
    return values[entryIndex];
  }
}
\end{lstlisting}
\end{figure}

\subsection{Option 2: Specialized Traversal Layouts}
For a certain class of kernels, where there is only one access to a sparse View, and the schedule traverses that data in order, a different approach could remove the check present in the first approach.

In this approach, each format has two implementations. 
One implementation performs a random access search, while the other traverse the data in order. 
If a programmer indicates the data will be traversed in order, or the runtime system can prove that it will, the View can be switched to the fast access format before kernel execution.

This approach has the benefit of faster access times at the cost of a smaller domain of possible kernels it could uspport. 
For example, it could not support a kernel that makes two accesses to the same View or one that makes multiple traveresals of the data, such as a matrix multiplication.

Abbreviated implementations of the formats are shown in Listing~\ref{specializedLayoutsImpl}.
\begin{figure}
\begin{lstlisting}[caption={Abbreviated format implementation for the Specialized Traversal Layout approach.},label=specializedLayoutsImpl]
class FastCOO {
  int currIdx = 0;
  \dots
  void preKernelLaunch() {
    currIdx = 0;
  }
  ElementType access(Idxs...indices) {
    return values[currIdx++];
  }
}
\end{lstlisting}
\end{figure}

\subsection{Option 3: Specialized Index Types}
The third option, like the second, uses an approach of dispatching to different access functions based on access pattern information.
Here, rather than using the View's layout type to select the access function, I use the type of the loop index values passed to the lambdas.
For example, the COO format may have two access functions, specialized for different inputs.
Listing~\ref{specializedIndexImpl} shows possible access functions fro the COO format.

This approach has the benefit of maintaining a single View layout type, avoiding the virtualization necessary to support the second approach.
This removes yet another source of overhead in the sparse access functions.
However, because it changes the type of the indexing variables, it imposes some of the same limitations as the symbolic evaluation functionality. 
Critically, all the data structures used in a kernel would need to support the different index types. 
For codes that only used dense and sparse Views, this is less of a problem.
For codes that access vectors or traditional arrays, this presents more serious issues.
Additionally, if two sparse Views are used in the same kernel, they both need to traverse their data in the efficient order.
This is because the same index type has to be used for both sparse Views.


\begin{figure}
\begin{lstlisting}[caption={Reference implementation for the Specialized Index Types approach.}, label=specializedIndexImp]

ElemetType access(int i0, int i1) {
  return searchAccess(i0,i1);
}
int fastIdx = 0;
ElementType access(FastIdx i0, FastIdx i1) {
  return values[fastIdx++];
}
\end{lstlisting}
\end{figure}

\subsection{Striking a Balance}
While the latter two options offer the potential for better performance than the first, it comes at a steep price of applicability.


\section{Evaluation}

To evaluate the prototype, I compare the performance of three versions of three benchmarks: sparse matrix vector multiplication (SpMV), Gauss-Seidel iteration (GauSei), and incomplete Cholesky factorization (InCholFact).
The first version, \dense, implements the computation on dense data. 
The second version, \specialized, is specialized for a particular sparse format by hand. 
The third version, \sparseraja, implements the computation using the prototype support described above.
In terms of representation, the expectation is that the \dense{} and \sparseraja{} versions of the code will look similar, both varying significantly from the format-specific implementation of the \specialized{} version.
In terms of performance, the \dense{} version is expected to be the outlier, as it executes many more iterations than the \sparseraja{} and \specialized{} versions.

\todo{description of GauSei}

\todo{description of InCholFact}

I also vary the size and nonzero density of the data.
I examine four data sizes: $2^n\times2^n$ for $n\in\{6,8,10,12\}$.
Similarly, I examine four nonzero densities: 50\%, 10\%, 1\%, and 0.1\%. 
Combined, this makes for $3*4*4=48$ versions of each of the three benchmarks.
I report the average of five runs.



\subsection{Benchmark 1: SpMV}
While a relatively simple computation on its own, sparse matrix vector multiplication (SpMV) is a foundational building block for sparse computations.
The computation has two pieces of input data: a sparse matrix \verb.A. and a dense vector \verb.x.. 
Each element of the single output vector \verb.y. is the dot product of the corresponding row of \verb.A. with the whole vector \verb.x..
Listings~\ref{DenseMV},~\ref{SpecializedMV}, and~\ref{SparseRAJAMV} show the reference implementations for the three versions of the computation.


\begin{figure}
\begin{lstlisting}[caption={RAJA implementation of dense matrix vector multiplication.},label=DenseMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
DenseView<2> A(Ni,Nj);

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::Lambda<0>
    >
  >
>;

auto seg1 = RangeSegment(0,Ni);
auto seg2 = RangeSegment(0,Nj);
auto segs = make_tuple(seg1, seg2);

auto lam = [&](auto i, auto j) {
  y(i) += A(i,j) * x(j);
};

auto knl = make_kernel<POLICY>(segs, lam);
knl();
\end{lstlisting}
\end{figure}
\begin{figure}
\begin{lstlisting}[caption={RAJA implementation of sparse matrix vector multiplication, specialized for COO storage.},label=SpecializedMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
DenseView<1> A_cols(NumNonZeros);
DenseView<1> A_rows(NumNonZeros);
DenseView<1> A_vals(NumNonZeros);

auto seg = RangeSegment(0,NumNonZeros);

auto lam = [&](auto idx) {
  auto i = A_rows(idx);
  auto j = A_cols(idx);
  y(i) += A_vals(idx) * x(j);
};

auto knl = make_forall<loop_exec>(seg, lam);
knl();
\end{lstlisting}
\end{figure}
\begin{figure}
\begin{lstlisting}[caption={Implementation of SpMV using the SparseRAJA prototype},label=SparseRAJAMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
SparseView<2> A(Ni,Nj);

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::Lambda<0>
    >
  >
>;

auto seg1 = RangeSegment(0,Ni);
auto seg2 = RangeSegment(0,Nj);
auto dense_segs = make_tuple(seg1, seg2);

auto lam = [&](auto i, auto j) {
  y(i) += A(i,j) * x(j);
}

auto knl = make_sparse_kernel<POLICY>(dense_segs, A, lam);
  
knl();
\end{lstlisting}
\end{figure}


\subsection{Benchmark 2: Gauss-Seidel Iteration}

The second kernel, Gauss-Seidel iterative solve, is a well-known kernel for approximating the solution to a linear system.
The problem of solving a linear system is thus: given a coefficient matrix $A$ and a right-hand side vector $b$, find a vector $x$ such that $Ax=b$.
The Gauss-Seidel method does this by starting with an initial guess and successively refining it to closer and closer approximations.
This process is repeated until a desired level of accuracy is reached.

While the kernel itself is applied iteratively to refine the approximation, we focus here on the operations of the iterations internal to the kernel.
An imperfectly nested, two-dimensional loop nest, GauSei updates each element of the solution vector $x$ in sequence.
First, the dot product of a row of $A$ and the current approximation is accumulated in a temporary variable.
Note that if the approximation is exactly correct, this value will be equal to the corresponding entry of $b$. 
The difference between the temporary and the right-hand side is then used to update the approximation, and the process repeats.

Gauss-Seidel is a tricky kernel because of its data dependences.
The results of earlier iterations change values used in subsequent ones, meaning that the order of the iterations cannot be changed arbitrarily. 
For this reason, GauSei cannot be represented as tensor algebraic expressions, placing it outside TACO's space of expressible computations.

Listings~\ref{DensGauSei},~\ref{SpecializedGauSei}, and ~\ref{SparseRAJAGauSei} show the three reference implementations of the GauSei kernel.
Because of the significant variations between the three implementations, I also show a C-like reference implementation in Listing~\ref{CppGauSei}.

One such variation appears in the \specialized{} version. 
Because specializing the implementation for the COO format flattens the iteration space from two dimensions to one, guard statements must be inserted to check for changes in rows. 
Furthermore, it also requires pulling part of the final iteration out of the loop.

\begin{figure}
\begin{lstlisting}[caption={C-like version of Gauss-Seidel iteration},label=CppGauSei]
View<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

while(!has_converged()) {
  for(int i = 0; i < N; i++) {
    temp = 0.0;
    for(int j = 0; j < N; j++) {
      if (j != i) {
        temp += A(i,j) * x(j);
      }
    }
    x(i) = (b(i) - temp) / A(i,i);
  }
}
\end{lstlisting}
\end{figure}

\begin{figure}
\begin{lstlisting}[caption={\dense{} version of Gauss-Seidel iteration},label=DenseGauSei]
View<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>,
    >,
    statement::Lambda<2>
  >
>;

auto lam1 = [&](auto i) {
  temp = 0.0;
};
auto lam2 = [&](auto i, auto j) {
  if (j != i) {
    temp += A(i,j) * x(j);
  }
};
auto lam3 = [&](auto i) {
  x(i) = (b(i) - temp) / A(i,i);
}

auto seg1 = RangeSegment(0,N);
auto seg2 = RangeSegment(0,N);
auto segs = make_tuple(seg1, seg2);

auto knl = make_kernel<POLICY>(segs, lam1, lam2, lam3);

while (!has_converged()) {
  knl();
}
\end{lstlisting}
\end{figure}

\begin{figure}
\begin{lstlisting}[caption={\specialized{} version of Gauss-Seidel iteration},label=SpecializedGauSei]
View<2> A_rows(NNZ);
View<2> A_cols(NNZ);
View<2> A_vals(NNZ);
View<1> b(N);
View<1> x(N) = initial_guess;

while (!has_converged()) {
  int prev_i = 0;
  double temp = 0.0;
  for(int idx = 0; idx < NNZ; idx++) {
    int i = A_rows(idx);
    int j = A_cols(idx);
    double v = A_vals(idx);

    if (i != prev_i) {
      double prev_diagonal = find(prev_i, prev_i, A_rows, A_cols, A_vals);
      x(prev_i) = (b(prev_i) - temp) / prev_diagonal;
      temp = 0.0;
      prev_i = i;
    }
    if (j != i) {
      temp += v * x(j);
    } 
  }
  double prev_diagonal = find(prev_i, prev_i, A_rows, A_cols, A_vals);
  x(prev_i) = (b(prev_i) - temp) / prev_diagonal;
}
\end{lstlisting}
\end{figure}


\begin{figure}
\begin{lstlisting}[caption={\sparseraja{} version of Gauss-Seidel iteration},label=SparseRAJAGauSei]
SparseView<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>,
    >,
    statement::Lambda<2>
  >
>;

auto lam1 = [&](auto i) {
  temp = 0.0;
};
auto lam2 = [&](auto i, auto j) {
  if (j != i) {
    temp += A(i,j) * x(j);
  }
};
auto lam3 = [&](auto i) {
  x(i) = (b(i) - temp) / A(i,i);
}

auto seg1 = RangeSegment(0,N);
auto seg2 = RangeSegment(0,N);
auto segs = make_tuple(seg1, seg2);

auto knl = make_sparse_kernel<POLICY, 2>(segs, A, lam1, lam2, lam3);

while (!has_converged()) {
  knl();
}
\end{lstlisting}
\end{figure}

\subsection{Benchmark 3: Incomplete Cholesky Factorization}

\todo{introduce what it does}

\todo{introduce data requirements}

\todo{discuss any notable characteristics.}

\todo{reference implementations}


\subsection{Performance Results}



\section{Limitations and Future Directions}

\section{Conclusion}




\begin{comment}
%concretize the problem 
\section{Case Study Computations}

Three sparse computations will form the case studies for this chapter: sparse matrix vector multiplication (SpMV), sparse Gauss-Seidel iterative solve (GauSei), and Incomplete sparse Cholesky Factorization (InCholFact). 

We begin with a discussion of their dense implementations.
Figure~\ref{DenseMV} shows the dense implementation of a matrix-vector multiplication.
While a relatively simple computation, matrix-vector multiplication is a foundational building block for a large swath of computations.
Figure~\ref{DenseGauSei} shows a dense implementation of the Gauss-Seidel method for solving a system of linear equations.
Considerably more complex than the matrix-vector multiplication, this computation exhibits both imperfect nesting (lines 7 and 13), and conditional statements within the loop (lines 9-11). 
Furthermore, unlike matrix-vector multiplication, where the only constraint on the execution schedule is the reduction into the \verb.y. View, Gauss-Seidel is restricted by the dependence between the read on line 10 and the write on line 13. 
Figure~\ref{DenseInCholFact} shows a dense implementation of the incomplete Cholesky factorization. 
Here, we see multiple loops within an outer loop (line 6-10 and 11-17), conditional statements within the loop bodies (lines 7-9 and 13-15), and function calls within the loop nest (line 5).



\begin{figure}
\begin{lstlisting}[caption={C-like implementation of dense incomplete Cholesky factorization},label=DenseInCholFact]

View<2> A(N,N);

for(i0 = 0; i0 < N; i0++) {
  A(i0,i0) = sqrt(A(i0,i0));
  for(i1 = i0+1; i1 < N; i1++) {
    if (A(i1,i0) != 0) {
      A(i1,i0) /= A(i0,i0);
    }
  }
  for(i1 = i0+1, i1 < N; i1++) {
    for(i2 = i1; i2 < N; i2++) {
      if (A(i2,i1) != 0) {
        A(i2,i1) -= A(i2,i0) * A(i1,i0);
      }
    }
  }
}

//fill upper triangle with zeroes
for(i0 = 0; i0 < N; i0++) {
  for(i1 = i0+1; i1 < N; i1++) {
    A(i0,i1) = 0;
  }
}
\end{lstlisting}
\end{figure}

Next, we consider implementations of these computations for sparse data stored using a row-major coordinate (COO) storage.
For SpMV, this code is straightforward, shown in Listing~\ref{COOMV}.
For each of the nonzero entries in \verb.A., we use its row and column indices to update the appropriate element of \verb.y..
However, for the other two computations, the process is not as straightforward.
Where in the SpMV case the two loop nests are collapsed into one, how should the code between the two loops be incorporated? 
In GauSei, where should the implementation reset the temporary? 
How do we know when to update \verb.phi.?


\begin{figure}
\begin{lstlisting}[caption={C-like implementation of sparse matrix vector multiplication for row-major COO.},label=COOMV]
SparseView<2, COO> A(Ni,Nj);
View<1> x(Nj), y(Ni);

for(int idx = 0; idx < A.nnz; idx++) {
  int i0 = A.rows(idx);
  int i1 = A.cols(idx);
  y(i0) += A.vals(idx) * x(i1);
}
\end{lstlisting}
\end{figure}
\begin{figure}
  \begin{lstlisting}[caption={C-like implementation of sparse Gauss-Seidel iterative solve for row-major COO.},label=DenseGauSei]
  SparseView<2,COO> A(N,N);
  View<1> b(N);
  View<1> phi(N) = initial_guess;
  
  while (!has_converged()) {
    for(int idx = 0; idx < A.nnz; idx++) {

    }
    for(int i = 0; i < N; i++) {
      temp = 0.0;
      for(int j = 0; j < N; j++) {
        if (j != i) {
          temp += A(i,j) * phi(j);
        }
      }
      phi(i) = (b(i) - temp) / A(i,i);
    }
  }
  \end{lstlisting}
  \end{figure}
  \begin{figure}
  \begin{lstlisting}[caption={C-like implementation of sparse incomplete Cholesky factorization for row-major COO.},label=COOInCholFact]
  
  View<2> A(N,N);
  
  for(i0 = 0; i0 < N; i0++) {
    A(i0,i0) = sqrt(A(i0,i0));
    for(i1 = i0+1; i1 < N; i1++) {
      if (A(i1,i0) != 0) {
        A(i1,i0) /= A(i0,i0);
      }
    }
    for(i1 = i0+1, i1 < N; i1++) {
      for(i2 = i1; i2 < N; i2++) {
        if (A(i2,i1) != 0) {
          A(i2,i1) -= A(i2,i0) * A(i1,i0);
        }
      }
    }
  }
  
  //fill upper triangle with zeroes
  for(i0 = 0; i0 < N; i0++) {
    for(i1 = i0+1; i1 < N; i1++) {
      A(i0,i1) = 0;
    }
  }
  \end{lstlisting}
  \end{figure}

Figures~\ref{DenseMV} and~\ref{SparseMV} show C-like implementations of the SpMV kernel using dense and sparse data formats, respectively.
Consider the extent to which the representations of the computations depend on the selected data format.
In the sparse implementation, the data format of \verb.A. changes not only the access to \verb.A., but also the bounds of the inner loop and even the access to the other data in the computation (\verb.x.).
All parts of the computation description have been tied up with the format of just one of the arrays.
This means that changes to the format of \verb.A. will require modifying nearly all parts of the computation, significantly reducing the flexibility of the code. 





\begin{figure}
\begin{lstlisting}[caption={C-like implementation of sparse matrix vector multiplication using compressed sparse row (CSR) format.}, label=SparseMV]
SparseView<2,CSR> A(Ni,Nj);
View<1> x(Nj);
View<1> y(Ni);

for(int i = 0; i < Ni; i++) {
  startIndex = A.rowptr(i);
  endIndex = A.rowptr(i+1);
  for(int j = startIndex; j < endIndex; j++) {
    y(i) += A.values(j) * x(A.col(j));
  }
})
\end{lstlisting}
\end{figure}

\end{comment}

\section{Design Overview}

With some relevant computations and their characteristics in mind, I now provide an overview of the designed system.
First, we have the interface for representing sparse data. 
We limit to a small set of sparse storage formats based on coordinate storage and compressed sparse row.
Second, we have the interface for representing a sparse computation.
This interface is based on the existing interface for representing dense computations.
Because the interface for sparse data is format-agnostic, the representation of a sparse computation looks almost identical to its dense counterpart.
As with dense codes, the programmer provides an iteration space tuple, an execution schedule, and lambdas to represent the statements within the loops.
Using the access information gathered through symbolic evaluation, the iteration space is sparsified and the data is prepared for efficient traversal.
Third, we have the interface for selecting / changing data formats for the computation. 
This interface is similar to that of \FormatDecisions, but supports sparse data formats.
Finally, we have computation execution, which traverses the sparse iteration space and runs the computation. 

While the design of the programmer's interface is relatively straightforward, its implementation presents numerous challenges.

\section{Design}







This section considers the decisions that are part of designing the sparse interface. 
I break the design down into four components.
The first component delimits the space of computation and data.
The second describes how programmers specify their computation, as well as the class of computations the interface supports.
The third describes how the runtime reduces the dense iteration space to just the points with nonzero data. 
The fourth describes how we iterate through sparse the data during kernel execution.

\subsection{Supported Sparse Formats}

Bootstrapping, I begin with a limited class of sparse tensors.
In analogy to the permuted layouts of RAJA's dense Views, consider the set of coordinate storage formats with different orderings of the coordinate entries.
I will refer to this set of formats as permuted coordinate storage (PCOO).
We can uniquely identify these formats with the permutation of their dimensions.

Consider next the two-dimensional sparse storage formats compressed sparse row (CSR) and compressed sparse column (CSC). 
Compare these formats with the $(0,1)$ and $(1,0)$ PCOO formats.
CSR compresses dimension zero and uses it to access dimension one, while CSC compresses dimension one and uses it to access dimension zero. 

A $>2$-dimensional PCOO format can be compressed in a similar manner by compressing the outermost dimension of the format. 
Each PCOO format only has one outermost dimension, so these compressed permuted coordinate (CPCOO) storage formats can also be identified with the permutation of their indices. 
CSR is the same as $CPCOO_{0,1}$ and CSC as $CPCOO_{1,0}$.
These two classes of formats, PCOO and CPCOO, are where I begin the design. 

\subsection{Supported Computation Space}

Constraints
\begin{itemize}
	\item Conditional statements within loop bodies must not contain View accesses in their conditional expression.
	\item View indexing expressions must be lone iterators rather than affine expressions of the iterators, as in previous chapters.
	\item All writes to sparse Views must be updates, not insertions of new nonzeros.
\end{itemize}



\subsection{Computation Interface}

The driving concern for the interface is that the details of which sparse formats the Views are stored in should be abstracted out of the computation description as much as possible. 
This means that the description of a sparse computation should look very similar to that of a dense computation. 

I introduce a new computation wrapper type, \verb.SparseKernelWrapper. to visually indicate that the computation should consider the sparsity of the data. 
Like the original \verb.KernelWrapper. type, I also introduce a \verb.make_sparse_kernel. function for creating sparse computation objects. 



\begin{figure}
\begin{lstlisting}

\end{lstlisting}
\end{figure}



\subsection{Sparsifying the Iteration Space}

Once the computation object has been created, the sparsity of its data must be used to reduce the iteration space to only the points where nonzero datapoints exist.
My approach proceeds in two phases: a symbolic representation phase and a execution phase. 


\begin{figure}
\begin{lstlisting}[caption={Algorithm to sparsify iteration space based on access to SparseView}]
haveCompressed = false;
compressedDim = -1;
for nest in nesting:
	if nest not in access:
		sparseSegs[nest] = segs[nest];
	else if haveCompressed:
		idx = access.indexOf(nest);
	sparseSegs[nest] = segs[nest] & view.dense_by(idx, compressedDim);
	else:
		idx = access.indexOf(nest);
		sparseSegs[nest] = segs[nest] & view.compressed(idx);
		haveCompressed = true;
		compressedDim = idx;

return sparseSegs;
\end{lstlisting}
\end{figure}


\subsection{Efficient Iteration Through Data}


\subsection{Permuted Coordinate Sparse Views}

Currently, two functions are supported that create sparse data structures: \verb.make_sparse_view. and \verb.make_permuted_sparse_view..
The former is a wrapper of the latter, generating a SparseView with the identity permutation.
For an $N$ dimensional SparseView, there are $N+2$ parameters to \verb.make_permuted_sparse_view..
The first $N$ parameters are vectors containing the index values for each dimension. 
This means that for a 2 dimensional SparseView, the first two arguments are the row and column indices of the entries.
The $N+1th$ parameter is a vector containing the entries themselves. 
Finally, the last parameter is the permutation vector for the SparseView. 
This section details how changes to the permutation vector change the behavior and storage of the SparseView.

The idea of the permutation vector is that it changes how the entries of the view are sorted, but not how they are referenced / indexed.
An example is warranted. 
Consider a sparse view containing the following entries, presented here unordered:
\begin{lstlisting}
DIM0: 0 1 2 1 0 2
DIM1: 1 1 0 2 2 0
DIM2: 1 0 2 1 0 0
VAL : A B C D E F 
\end{lstlisting}
If these entries are used to construct the standard SparseView, they will be reordered and stored as follows:
\begin{lstlisting}
DIM0: 0 0 1 1 2 2
DIM1: 1 2 1 2 0 0
DIM2: 1 0 0 1 0 2
VAL : A E B D F C
\end{lstlisting}
If the SparseView is constructed with the permutation vector $(2,0,1)$, they will be stored as:
\begin{lstlisting}
DIM0: 0 1 2 0 1 2
DIM1: 2 1 0 1 2 0
DIM2: 0 0 0 1 1 2
VAL : E B F A D C
\end{lstlisting}
Note that the list of dimensions is not permuted, only the order the entries are sorted. 

What this scheme means is that no matater the permutation, the access \verb.view(0,1,1). will always return \verb.A., even if its location in the list of entries changes.

The permutation scheme becomes more complicated when considering the sparsification of an iteration space based on an access to a SparseView, especially when dependences are present. 
The interaction between RAJA kernel policy execution and the permuted data structure creates a challenge. 
I turn now to a short investigation of RAJA kernel policies to elucidate this challenge.

\subsection{Kernel Policies for Sparse Computations}

I begin this investigation with the following two dimensional kernel:
\begin{lstlisting}
using POLICY = KernelPolicy<
  statement::For<0,seq_exec,
    statement::For<1,seq_exec,
      statement::Lambda<0>
    >
  >
>;

auto segments = make_tuple(RangeSegment(0,2), RangeSegment(3,5));

kernel<POLICY>(segments, [=](auto i0, auto i1) {
  std::cout << i0 << "," << i1 << "  ";
});
\end{lstlisting}
From this kernel, we would expect the output to be \verb.0,3  0,4  1,3  1,4..

Next, consider the same kernel with the following slightly modified kernel policy:
\begin{lstlisting}
using POLICY = KernelPolicy<
  statement::For<1,seq_exec,
    statement::For<0,seq_exec,
      statement::Lambda<0>
    >
  >
>;
\end{lstlisting}
With this policy, the outer for loop will increment the second segment and the inner loop will increment the first.
Thus, the expected output would be \verb.0,3  1,3  0,4  1,4..

Finally, consider a different modification to the kernel policy:
\begin{lstlisting}
using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::Lambda<0>
    >
  >
>;
\end{lstlisting}
Here, the loop-level execution policies have changed from \verb.seq_exec. to \verb.loop_exec..
And while this has changed, we still would expect the output to be \verb.0,3  0,4  1,3  1,4..
So what has changed? 
Something quite subtle about the semantics. 
The \verb.seq_exec. policy demands \enquote{strictly sequential execution,} whereas \verb.loop_exec. \enquote{allow[s] the compiler to generate any optimizations that its heuristics deem beneficial}~\cite{rajadocs}.

Now, why is this relevant? 
It is relevant because these concepts must be mapped to sparse computation in a way that is intuitive but still enables efficient execution on the backend.
So the question here is: what constraints on the sparse schedule are imposed by the use of policies with either \verb.seq_exec. or \verb.loop_exec.?

One thing is somewhat clear: regardless of the loop-level execution policy, kernel execution should be implemented as two nested for loops. 
Further, the for loops should traverse the dimensions indicated in the policy. 
This means the difference between \verb.loop_exec. and \verb.seq_exec. is constrained to an individual loop level. 

Once more, why is this relevant? 
The relevance comes from the the task of sparsifying an iteration space when the traversal order of the iteration space does not match the storage order of the sparse data.
If the iteration space traversal order is a strict constraint, then there are two options.
Either we reorder the sparse data to match the traversal order, or we perform a \enquote{trivial sparsification,} returning the original dense iteration space.

\subsection{A Constraint of Idiomatic RAJA}

The challenge of the previous subsection uncovers a constraint imposed by the RAJA library's design.
RAJA's execution strategy is based on the enumeration of a cross product. 
Every combination of values in the segments is visited.
For a sparse iteration space, this approach fails.
Rather than enumerating a cross product, a sparse computation must iterate over each dimension simultaneously. 
The values of $j$ when $i=0$ are different from the values of $j$ when $i=1$. 

The core of the problem here is that the inner dimensions of a loop must not be static. 
They must be able to change as the outer iterators change.

\subsection{Another Problematic Example}

Consider the following kernel for a square, sparse matrix \verb.A. in the unpermuted COO format:
\begin{lstlisting}

using POLICY = KernelPolicy<
  statement::For<0, loop_exec,
    statement::For<1, loop_exec,
      statement::Lambda<0>
    >
  >
>;
auto segments = make_tuple(seg, seg);
auto lam = [&](auto i, auto j) {
  z(i) += A(i,j) * y(j);
}

kernel<POLICY>(segments, lam);
\end{lstlisting}
In this computation, we have a nesting order $(0,1)$, a layout order $(0,1)$, and an access order $(0,1)$. 
We can sparsify the iteration space without changing the layout.

Now, what if we were to change the access order? 
\begin{lstlisting}
auto lam2 = [&](auto i, auto j) {
  z(i) += A(j,i) * y(j);
}
\end{lstlisting}
Now, the access order has changed from $(0,1)$ to $(1,0)$. 
The $(i,j)$th iteration is no longer accessing the $(i,j)$th element of \verb.A. 
When we sparsify an iteration space, we must maintain all iterations where a nonzero element is accessed. But we must remove the unnecessary iterations without reordering the remaining.
So in this case, we have the following iteration space ${[i,j] | A[j,i] != 0}$
Before considering how it is to be calculated, we can observe that for efficient iteration, the data in \verb.A. must be sorted in the order $(1,0)$. 
This is because the inner loop is indexing the first dimension of \verb.A. and the outer loop is indexing the second dimension. 

Changes to the layout order do not change the semantics. Changes to the access order and nesting order do change the semantics.

\subsection{Sparsifying the Iteration Space}

We begin with the case of an iteration space and square view with equal dimensionality.
Let the iteration space be $I = \{[i_0,i_1,...,i_n] | C\}$ for some constraints $C$.
We seek to sparsify based on an access $A(i_{p(0)},i_{p(1)},...i_{p(n)})$ for a permutation $p$.
This is equivalent to calculating the set $I_s = \{[i_0,i_1,...,i_n] | C \land A(i_{p(0)},i_{p(1)},...i_{p(n)}) \neq 0\}$.

Let $E_A$ indicate the indices of the nonzeros entries of $A$. 
Formally, $E_A = \{[i_0,i_1,...,i_n] | A(i_0,i_1,...,i_n) \neq 0\}$.
Claim: for the identity permutation $p$, $E_A = I_s$.

Proof: => 
consider $e = [e_0,e_1,...,e_n] \in E_A$. 
Because it is in $E_A$, we have $A(e) \neq 0$.
Thus, if $e$ satisfies the constraints $C$, the $e$ is an element of $I_s$.
Square view and iteration space, so it must.

Proof: <=
Consider $i$ in $I_s$. 
We thus have $A[p(i)] \neq 0$.
Because $p$ is the identity permutation, we have $p(i) = i$, so $A[i] \neq 0$, so $i \in E_A$.

Next, let's turn to an arbitrary permutation $p$. 
Again let $q$ be the inverse permutation of $p$. 
Claim: $q(E_A) = I_s$.

Proof: => 
consider $e = [e_0,e_1,...,e_n] \in q(E_A)$.
If we apply the permutation $p$, we have $p(e) \in p(q(E_A))$.
Thus, $[e_{p(0)},e_{p(1)},...,e_{p(n)}] \in p(q(E_A)) = E_A$, as $p$ and $q$ resolve to the identity permutation.
Then, by the definition of $E_A$, we have $A(e_{p(0)},e_{p(1)},...,e_{p(n)}) \neq 0$. 
Thus, if $p(e)$ satisfies constraints $C$, $p(e) \in I_s$. 

Proof: <=
consider $i = [i_0,i_1,...,i_n] \in I_s$. 
By the definition of $I_s$, we have $A(i_{p(0)},i_{p(1)},...,i_{p(n)}) \neq 0$.
This means that $p(i) \in E_A$.
Finally, applying the permutation $q$ gives $q(p(i)) \in q(E_A)$, or $i \in q(E_A)$.

Let's do an example to make this more concrete.
Three dimensional iteration space $I = [0,N]^3$.
Access to sparse data $A(i_2,i_0,i_1)$. 
So $p=(2,0,1)$.
The inverse of this permutation is $q=(1,2,0)$.
We're looking for the set $I_s = \{[i_0,i_1,i_2] | A(i_{p(0)},i_{p(1)},i_{p(2)}) \neq 0\}$. 
Simplified with the definition of $p$, $I_s = \{ [i_0,i_1,i_2] | A(i_2,i_0,i_1) \neq 0\}$.

Say that $A$ has the following data:
\begin{lstlisting}
dim0 = {0,0,0,1,1,2,2};
dim1 = {1,2,2,1,2,0,0};
dim2 = {0,0,2,0,1,1,2};
   v = {1,2,3,4,5,6,7};
\end{lstlisting}
Consider the data point at $(0,1,0)$ holding value $1$. 
On iteration $(1,0,0)$, the access made will be to $A(0,1,0)$.
On iteration $(0,1,2)$ the access will be made to $A(2,0,1)$.
So to go from iteration to access, we apply $p$. 
To go from access to iteration, we apply $q$.
Since we want to calculate the iteration space points that access data in $A$, we want to apply $q$ to the data space of $A$.

While the nesting order of a kernel changes the schedule of the execution, it does not change which points are actually in the iteration space.
Thus, the procedure of applying the inverse permutation of the access order to the data space will produce the sparsified iteration space, which can then be scheduled using the nesting order.

With the case of square, size-matched iteration and data spaces, let's expand to the case of a nonsquare iteration and data spaces.
For a concrete example, let's consider the iteration space $I = \{[i_0,i_1,i_2] | 0 \leq i_0 \leq N_0 \land i_0 \leq i_1 \leq N_1 \land i_0 \leq i_2 \leq i_1 \}$.
Let's sparsify this space based on the access $A(i_2,i_1,i_0)$. 
The access permutation $p=(2,1,0)$, and its inverse is the same.
The set we want to calculate is $I_s = \{[i_0,i_1,i_2] | 0 \leq i_0 \leq N_0 \land i_0 \leq i_1 \leq N_1 \land i_0 \leq i_2 \leq i_1 \land A(i_2,i_1,i_0) \neq 0 \}$.

We calculate this in parts. 
First, we identify the iteration space points that access a nonzero. 
Then, we apply the original constraints on the iteration space. 

At this point, calculating the sparsified iteration space proceeds with the following algorithm:
\begin{lstlisting}
auto sparsify_equal_dims(IterationSpace denseSpace, SparseAccess access) {
  auto q = invert(access.orderPermutation);
  auto view = access.accessedView;
  
  auto sparseRect = [];
  auto leadDimension = SparseSegmentLead(view, q[0]);
  sparseRect.push_back(leadDimension);
  for(int i = 1; i < view.numDims; i++) {
    auto dim = SparseSegmentFollow(view, q[i], &leadDimension);
    sparseRect.push_back(dim);
  }
  return IterationSpace(sparseRect, denseSpace.constraints);
}
\end{lstlisting}
Of course, this algorithm sidesteps the question of how the original constraints are applied to the sparsified iteration space.
But that is a problem to be addressed in the discussion of the implementation.
The important piece here is the general process. 
Invert the function that takes us from the iteration space to the data space, then use that function to construct an iteration space that only contains points that access the nonzeros.

Thus far, we have only considered the case where $dims(A) = dims(I)$.
This leaves two more cases to consider. 
We begin with the case where $dims(I) > dims(A)$. 
Such a situation arises in computations like matrix multiplication.
Here, the abstraction of the access as a permutation begins to break down. 
For example, consider the case of $I=[0,N]^3$ and access $A(i_0,i_2)$.
The set we want to calculate is $I_s = \{[i_0,i_1,i_2] | A(i_0,i_2) \neq 0 \land 0 \leq i_0 \leq N \land 0 \leq i_1 \leq N \land 0 \leq i_2 \leq N\}$.

A helpful observation: changes to indices that do not appear in the access do not affect whether the iteration accesses a nonzero.
Thus, we can temporarily set aside those dimensions.
So we want to calculate $I\prime_s = \{[j_0,j_1] | A(j_0,j_1) \neq 0\}$, which we do using the algorithm shown above.
Finally, we bring back the invariant dimensions, giving us $I_s = \{[i_0,i_1,i_2] | [i_0,i_2] \in I\prime_s \land \land 0 \leq i_0 \leq N \land 0 \leq i_1 \leq N \land 0 \leq i_2 \leq N\}$

So the algorithm here becomes:
\begin{lstlisting}
auto sparsify_i_gt_a(IterationSpace denseSpace, SparseAccess access) {
  variantDims = [idx for idx in denseSpace.indices if idx in access.indices];
  sparsified = sparsify_equal_dims(variantDims, access);
  
  sparseRect = emptyList(denseSpace.numDims);
  for(int i  = 0; i < denseSpace.numDims; i++) {
    if (denseSpace.indices[i] in variantDims) {
      sparseRect[i] = sparsified.map(i);
    } else {
      sparseRect[i] = denseSpace[i];
    }

    return IterationSpace(sparseRect, denseSpace.constraints);
  }
}
\end{lstlisting}
Where \verb.sparsified. holds some map of the iterator name to its position in the variant space.



\section{RAJA's Execution Model, In Depth}

While running, a kernel execution's state is maintained in a \verb.LoopData. object.
It contains a wrapped segment tuple, a param tuple, a resource object, and a parameter pack of body functors.
Here, we are interested in the process of wrapping the segment tuple. 
This process, implemented in \verb.make_wrapped_tuple., converts the tuple of segments to a tuple of \verb.Span. objects. 
Each \verb.Span. is initialized with the \verb.begin(). and \verb.end(). results of the corresponding entry of the segment tuple.
The \verb.Span. structure has two template arguments, an iterator type and an index type.

The tuple of \verb.Span. objects are referred to throughout kernel execution, through its own iterator interface. 
This interface either returns one of the iterators passed to its initialization, or a operator applied to it.
\verb.front. and \verb.back. dereference, \verb.back. and \verb.size. apply subtraction of integer and iterator, respectively.
Finally, \verb.operator[]. passes the operator on to the contained begin iterator.

\textit{The challenge here is creating a single segment tuple type that can represent the result of any of the possible transformations.}

Now, why was this not a problem when the dimensionalities are equal? 
Because the \textit{type} order of the tuple was always the same--one LeadSegment followed by N-1 FollowSegments--even while the dimension indices of the segments changed with the analysis results.
With the inequality cases, the order of the different segment types changes. 
Concretely, the difference is between the type \verb.tuple<DenseSegment,LeadSegment,FollowSegment>. and \verb.tuple<LeadSegment,FollowSegment,DenseSegment>..

One option forward is to reduce the number of types. 
However, see that we would have to reduce the number of types to one.
If we represent DenseSegment and LeadSegment with one type, say \verb.DLSegment., we still must reconcile the difference between \verb.tuple<DLSegment,DLSegment,FollowSegment>. and \verb.tuple<DLSegment,FollowSegment,DLSegment>..

Call this single segment type the \verb.SparseSegment..
This type needs to function as a wrapper for the different segment functionalities that the system will support.
It must have \verb.begin(). and \verb.end(). methods that create iterator objects, all still of the same type.
Call this iterator type  \verb.SparseIterator..

The \verb.SparseIterator. type needs to support the bracket operator and the minus operator. 
Here, the logic of the different types of segments can finally show itself through virtualization.
Here is a sketch of the \verb.SparseIterator. operators:
\begin{lstlisting}
struct SparseIteratorImpl {
  virtual idx_t & access(size_t i);
  virtual idx_t index();
}

struct DenseIteratorImpl : SparseIteratorImpl {
  camp::idx_t value;
  idx_t & access(size_t i) {
    return value + i;
  }
  idx_t* index() {return value;}
}

struct LeadIteratorImpl : SparseIteratorImpl {
  std::vector<idx_t> dimension;
  idx_t offset;
  size_t * currVal;
  idx_t & access(size_t i) {
    *currVal = i;
    return dimensionIterator[offset + i];
  }
  idx_t index() {
    return offset;
  }
}

struct FollowIteratorImpl : SparseIteratorImpl {
  std::vector<idx_t> dimension;
  idx_t offset;
  LeadSegmentImpl * leader;
  idx_t & access(size_t i) {
    return dimension[offset + leader->currVal + i];
  }
  idx_t index() {
    return offset;
  }
}

struct SparseIterator {
  SparseIteratorImpl * impl;
  idx_t & operator[](size_t i) {
    return impl->access(i);
  }
  idx_t operator - (SparseIterator other) {
    return 
  }
}

struct SparseSegmentImpl {
  virtual SparseIterator begin();
  virtual SparseIterator end();
}

struct DenseSegmentImpl : SparseSegmentImpl {
  idx_t low, high;
  DenseIteratorImpl * implLow;
  DenseIteratorImpl * implHigh;
  DenseSegmentImpl(idx_t l, idx_t h) : low(l), high(h) {
    implLow = new DenseIteratorImpl(low);
    implHigh = new DenseIteratorImpl(high);
  }
  SparseIterator begin() {
    return SparseIterator(implLow);
  }
  SparseIterator end() {
    return SparseIterator(implHigh);
  }
}

struct LeadSegmentImpl: SparseSegmentImpl {
  std::vector<idx_t> dimension;
  LeadIteratorImpl * implLow = new LeadIteratorImpl(dimension, 0, &currVal);
  LeadIteratorImpl * implHigh = new LeadIteratorImpl(dimension, dimension.size(), &currVal);
  idx_t currVal;
  SparseIterator begin() {
    return SparseIterator(implLow);
  }
  SparseIterator end() {
    return SparseIterator(implHigh);
  }
}

struct FollowSegmentImpl : SparseSegmentImpl {
  std::vector<idx_t> dimension;
  LeadSegmentImpl leader;
  FollowIteratorImpl * implLow = new FollowIteratorImpl(dimension, 0, &leader);
  FollowIteratorImpl * implHigh = new FollowIteratorImpl(dimension, 1, &leader);

  SparseIterator begin() {
    return SparseIterator(implLow);
  }
  SparseIterator end() {
    return SparseIterator(implHigh);
  }
}

struct SparseSegment {
  SparseSegmentImpl * impl;
  SparseIterator begin() {
    return impl->begin();
  }
  SparseIterator end() {
    return impl->end();
  }
}
\end{lstlisting}









\begin{lstlisting}

using POL=KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::For<2,loop_exec,
        statement::For<3,loop_exec,
          statement::Lambda<0>
        >
      >
    >
  >
>;

auto mttkrp_lam = [&](auto i0, auto i1, auto i2, auto i3) {
  A(i0,i1) += B(i0,i2,i3) * D(i3,i1) * C(i2,i1);
};

auto sparsified = sparsify(dense_segs, B, {0,2,3});
auto knl = make_sparse_kernel<POL>(sparsified, mttkrp_lam);

knl();
\end{lstlisting}



\section{Implementation}

\section{Evaluation}

\section{Discussion}
\section{Conclusion}