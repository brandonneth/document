\chapter{Sparse Transformations}\label{chap:sparseRAJA}
\chapterabstract{
Performance portability libraries like RAJA and Kokkos are a growing approach to the maintainability problems of large applications. 
While these libraries can productively represent and efficiently execute many computations, they lack robust support for an important type: sparse computations. 
Sparse computations are widespread, present in the solvers of large simulation codes, economic optimization problems, search engines, and recommendation systems. 
While it is technically possible to implement some sparse computations in RAJA, users cannot write sparse codes in a way that respects the abstractions provided by RAJA to think about and program the problem, most importantly the abstractions of multi-dimensional data and loops.
Furthermore, changing the format of the sparse data becomes a porting task that touches every part of the code. 
Rather than relying on existing approaches to sparse computations, which use domain-specific languages and compilers to generate efficient implementations, my approach incorporates the abstractions into the RAJA library itself. 
RAJA already contains a strong separation of the components of a computation: the operation, data, iteration space, and schedule. 
The key idea of my approach is to treat the sparsity as its own component in the RAJA program. 

The challenges of this approach lie in achieving good performance without losing portability. 
Two emerge specifically: constructing / traversing a sparse iteration space and accessing data without using searches. 
For the problem of the iteration space and schedule, I use leader and follower iterators to represent and traverse sparse iteration spaces, built on the symbolic iteration space capabilites I developed to support dense triangular iteration spaces. 
This approach supports coordinate storage, and I show how it can be extended to support compressed row and column storage formats. 
To efficiently traversal of the sparse structures, I incorporate an expected next access cache, inspired by prefetching systems.

}


\section{Sparse Computations and Data}

Sparse computations have long been a bottleneck for high performance computing applications. 
Even as early as 1971, scientists lamented the difficulty of computing with sparse data~\cite{willoughby1971sparse}.
Fifty years later, although the application domains have changed, programming sparse applications is still something of an open problem.
While sparse computations are still foundational to physics simulations, new domains have emerged, including prediction and recommendation/review systems.

\subsection{What is a Sparse Computation? 2 Examples.}

``Sparse'' describes data, and through it everything else. 
A simple definition for sparse data is data where the nonzero density is less than 0.1 or conversely, where more than 90\% of the entries are zero.
Other definitions are slightly less clear cut but more useful, defining a sparse matrix as one where there is advantage to be taken of the percentage or distribution of zero elements~\cite{duff1977survey}.

1.
Consider a local library that wishes to track people's ratings of its holdings.
One way to do this would be to construct a two-dimensional table, with a column for every title in the library and a row for every library member
As people submitted ratings, the corresponding entry in the table is then updated.
Now, library users do not often check out even 1\% of a library's titles across their entire lifetime.
This means that this enormous table of user ratings will always be almost completely empty.
It would be uneconomical to store this table as a 2D array when nearly all of those entries will never be used.
Instead, another approach to storing the data is necessary.
A much more scalable option, although certainly not optimal, would be to maintain a list of entries, where each entry contained the user's name, the title they rated, and their rating.
With this scheme, the amount of storage used is proportional to the number of ratings in the system rather than how many titles and users the library has.
The system here uses a sparse data structure that is \textit{mutable}, or written to after initialization.

2. 
In the realm of high performance computing, solving systems of linear equations is ubiquitous.
The systems of linear equations are often enormous, with a variable in the system for each point in the simulation's decomposition.
Importantly, each point in the simulation is connected to a limited number of other points, usually only the points directly around it.
This means that in the system's coefficient matrix, most entries will be zero, as the nonzero entries represent connections and relationships between different points.
The sparse computation here differs from the local library's in two key ways.
First, the sparse data is \textit{immutable}, meaning once the sparse matrix is constructed it is not changed.
Second, the operations performed on the data are much more expensive than the library's.
For example, the multiplication of a sparse matrix with a dense vector, executed many times during the solution of a system of equations, compared to the insertion of a new rating at the library.

\subsection{Challenges Working with Sparse Computations}

The central challenge when working with sparse data is the bandwidth and latency of a system's memory.
Because of the indirection and compression strategies used to only store nonzero values, many more cycles are spent getting the necessary data into the CPU than in a dense computation.
To improve this situation, researchers have developed countless different storage formats, each geared towards different processor types, algorithms, and data characteristcs.

There are general purpose formats like coordinate storage (COO) and compressed hyperplane storage (CHS)~\cite{ahmed2000compiling}, of which compressed sparse row (CSR)~\cite{gustavson1972some} and compressed sparse column (CSC) are instances.
There are banded formats, best for data with most entries clustered along the diagonal~\cite{jennings1966compact}, and jagged formats best for parallelized iterative algorithms~\cite{saad1989krylov,montagne2004optimal}.
There are formats specialized for GPUs~\cite{fan2004gpu,bell2009implementing,bell2008efficient,monakov2010automatically} and formats for FPGAs~\cite{sun2007sparse,kestur2012towards,fowers2014high}.
Then of course there are specializations to the general purpose formats, like doubly~\cite{buluc2008representation} --- or even triply~\cite{mofrad2019efficient} --- compressed sparse formats for data with many completely empty rows and blocked compressed sparse row~\cite{vuduc2005fast} for avoiding communication in distributed settings.
The list of sparse formats is seemingly endless, and each format requires its own specialized implementation.

There have been many approaches to reduce the impact of this variety: general sparse formats, standardized libraries, and sparse compilation.
General sparse formats allow for a uniform interface for sparse data, but fail to leverage valuable data characteristics to improve memory usage and arithmetic intensity.
Standardized solver libraries~\cite{eisenstat1977yale,eisenstat1977yale2,eisenstat1984new,kincaid1982algorithm,chu1980user,george1984new,marsten1981design,saad1990sparskit,falgout2006design} abstract away data traversal entirely, improving maintainability at the cost of requiring an application use its formats and functions.
Compilation approaches~\cite{ahmed2000compiling,ahmed2000framework,bik1993automatic,bik1996automatic,bik2022compiler} make writing code easy, and offer good performance, but support a limited range of computations and introduce build system complexities and fragilities.
Also, there is the cost of switching code to use that compiler's language instead of the one its already written in.

Each of these options suffers in either performance, productivity, or portability.
Performance portability libraries like RAJA~\cite{hornung2014RAJA}, Kokkos~\cite{edwards2014kokkos}, and YAKL~\cite{norman2022portable} strike a great balance here, but offer little support for sparse computations.
Many of the abstractions that a programmer would use to think about a computation, like multi-dimensional data and nested loops, do not transfer to the domain of sparse computation.
This is because rather than programming to their conceptual model, they must program to the specific format and schedule they seek to use.
Most of the code ends up implementing the traversal of the data structures rather than the computation the programmer wants to express.

\subsection{Contributions}

My approach explores the possibilities of incorporating some of the advances in sparse computations developed in previous approaches into a performance portability library.
The approach builds on the strong separation of concerns present in the RAJA library, taking it a step further by treating the sparsity of the data as its own component.
By isolating the sparsity as its own concern, it becomes more straightforward to specify its structure, as well as how it interacts with the other components of a RAJA computation.
This technique ensures an extension to the library that is comprehensible, flexible, and aligned to the existing features and feel of RAJA.

One of the central challenges to this approach is that it lacks the code generation capabilities present in compiler approaches.
For example, a code generating approach can translate a format-agnostic description of a computation into an optimized implementation for a specific format.
The approach I develop here is meant to use only standard C++ features and compilers, and because loop bodies in RAJA are given as lambda closures, I cannot rewrite (or even directly inspect) the operations they perform.
Instead, I use symbolic evaluation to perform analysis at runtime, then construct a sparse iteration space and incorporate a technique for efficient access directly into the call operator of the sparse data structure.

This chapter contains the following contributions:
\begin{itemize}
\item An interface for format-agnostic representation of sparse computations in the RAJA performance portability library.
\item An approach for the partial automation of the construction of a sparse iteration space.
\item An approach for efficient access of sparse data without requiring the code generation capabilities of compiler-based approaches
\item A prototype implementation of these components for two classes of sparse formats
\end{itemize}


\section{Design Considerations}
Unlike approaches that develop a entirely new system for supporting sparse computations, this approach is developed as part of an existing performance portability library.
This imposes novel constraints, namely that the extensions presented herein must \textit{build} on the existing abstractions, rather than replace or reformulate them.
Conveniently, RAJA already provides a strong separation of the components of a computation and an approachable interface for recomposing them.
This section presents versions of matrix vector multiplication to illustrate these features of RAJA and their limitations in expressing sparse computations.


\subsection{Matrix Vector Multiply, Dense and Sparse}
\begin{figure}
\begin{lstlisting}[caption={Matrix vector multiply routines for matrices in different formats.},label=DenseAndSparseMV]  
//Dense
void dense_matrix_vector_multiply(View2D A, View1D x, View1D y) {
  int Ni = A.num_rows();
  int Nj = A.num_cols();
  for(int i = 0; i < Ni; i++) {
    for (int j = 0; j < Nj; j++) {
      y(i) += A(i,j) * x(j);
    }
  }
}

//Coordinate storage
void COO_matrix_vector_multiply(COOView2D A, View1D x, View1D y) {
  int nnz = A.numNonZeros();
  for(int idx = 0; idx < nnz; idx++) {
    int i = A.rows(idx);
    int j = A.cols(idx);
    y(i) += A.vals(idx) * x(j);
  }
}

//Compressed Sparse Row
void CSR_matrix_vector_multiply(CSRView2D A, View1D x, View1D y) {
  int Ni = A.numRows();
  for(int i = 0; i < Ni; i++) {
    startIndex = A.rowptr(i);
    endIndex = A.rowptr(i+1);
    for(int j = startIndex; j < endIndex; j++) {
      y(i) += A.vals(j) * x(A.col(j));
    }
  }
}
}
\end{lstlisting}
\end{figure}
\begin{figure*}
  \centering
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[page=1,width=\textwidth]{FormatDiagram.pdf}
    \caption{Dense represention of data. Nonzero entries are colored by their row value.}\label{FormatDiagram:Dense}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \includegraphics[page=2,width=0.95\textwidth]{FormatDiagram.pdf}
    \caption{Coordinate storage represention of data. Nonzero entries are colored by their row value.}\label{FormatDiagram:COO}
  \end{subfigure}

  \begin{subfigure}[c]{0.45\textwidth}
    \includegraphics[page=3,width=0.95\textwidth]{FormatDiagram.pdf}
    \caption{Compressed sparse row represention of data. Nonzero entries are colored by their row value.}\label{FormatDiagram:CSR}
  \end{subfigure}
\caption{Dense, COO, and CSR storage representations of the same data.}\label{FormatDiagram}
\end{figure*}

Listing~\ref{DenseAndSparseMV} shows C-like implementations of the SpMV kernel using dense and sparse data formats.
The first implementation shows the computation written for a dense matrix.
The second implementation shows the computation written for coordinate storage (COO). 
In this format, the View contains three vectors: one for the row indices, one for the column indices, and one for the nonzero values.
These vectors contain as many elements as there are nonzero values.
The third implementation shows the computation written for a View in compressed sparse row storage (CSR).
This storage format is based on COO, but rather than storing every element of the row vector, it is compressed to a vector of offsets that indicate the start of each row within the column and value vectors.
Figure~\ref{FormatDiagram} shos a graphical representation of the three formats.



Consider the extent to which the representations of the computations depend on the selected data format.
In the sparse implementation, the data format of \verb.A. changes not only the access to \verb.A., but also the bounds of the inner loop --- now a function of the entries of \verb.rowptr.--- and even the access to the other data in the computation (\verb.x.).
All parts of the computation description have been tied up with the format of just one of the arrays.
This means that changes to the format of \verb.A. will require modifying nearly all parts of the computation, significantly reducing the flexibility of the code.


\subsection{RAJA's Flavor of Decomposition}
The previous subsection showed how different sparse formats need to be handled when changing sparse formats by hand.  
In this subsection, I discuss RAJA's approach to decomposition and the constraints it places on my approach of providing a way to specify the sparse computation without having to rewrite the loops.

As discussed in previous chapters, a RAJA computation is broken up into a description of the operation, the iteration space, the schedule, and the data format.
The main idea of my approach is to introduce an additional component for the sparsity of the data.
Then, the problem of extending RAJA to support sparse computations is reduced to identifying how this new sparsity should interact with each of the existing components.

The operation of the computation is provided by the user as lambdas that execute the iterations of a loop. 
Because the operation involves accessing sparse data, it presents strong constraints on the design of the sparse extension. 
Most importantly, the operation of the loop nest should be written the same regardless of the format. 
The natural candidate here is the existing interface for data access in dense RAJA codes: the call operator. 
While using the call operator to support accesses to sparse data produces an attractive interface for describing a computation, it surfaces the challenge of devising an access function that traverses the sparse data efficiently throughout a computation. This problem and my solution are discussed in Section~\ref{sec:SparseAccess}.

For the iteration space, we take a similar approach of format-agnostic specification.
The programmer describes the iteration space as if its a dense code then use the sparsity of the data to exclude iteration space points that do not access nonzero data.
This can be partially automated as part of the construction of the computation object, or done ahead of time by the programmer.
The automated process involves using the access information extracted from the operation to determine which iteration space points need to be retained.

The approach of augmenting a dense-like specification continues into the description of the schedule. 
The central challenge here is related to the construction of the sparse iteration space. 
As the sparse space is created out of the dense one, its representation needs to be compact and easily traversable by RAJA's kernel execution. 

Finally is the data format, where the sparsity plays a greater role.
While I restrict the prototype to COO and CHS formats, the dimensional ordering still plays an important role.
This is because the particulars of the data storage order influence the efficency of contsructing the sparse iteration space and traversing through the data.
Regardless of the underlying representation, the layout of the sparse view supports the standard multi-dimensional indexing functions that are used to access dense data.

\subsection{Computational Complexity}

Even for computations that only executes iterations that access a nonzero value, application performance depends on the speed the sparse data can be accessed.
Without any optimizations, each access to sparse data requires searching. 
Each dimension in the index hierarchy must be searched for the corresponding value, until either the entry is found or it can be determined that the entry is a zero.
In the worst case, for a View with $D$ dimensions and $NNZ$ nonzero entries, the complexity of a single access is $O(D * \log(NNZ))$. 
This is compared to $O(D)$ for a dense View.

Requiring a search on every access to a sparse structure is prohibitively expensive, but it is possible to reduce the complexity to constant time.
Specifically, if the computation uses a schedule and format that access and store the data in exactly the same order, then the search can be avoided entirely.
Instead, the index into the View's data is updated incrementally, processing the data in order.

In implementations written by hand or with code-generating approaches, incremental updates are hard-coded into the loop's implementation, either by the programmer or the compiler.
Each format requires a unique implementation that traverses its entries in the appropriate order, so code written for one format will not work for another.
My approach incorporates parts of this incremental update technique without requiring the code to be rewritten for each desired format. 
This involves maintaining a field in the SparseView that tracks its most recent access.
Then, when accessed, the view checks if the indices are for the entry stored next in the data. 
If so, the view can bypass the searching and immediately return the desired value. 
If not, the view performs the search as to return the correct value. 
This approach, a sort of software prefetching, does incur the overhead of a comparison between the current access and the expected access, but this $O(D)$ check is much faster than the $O(D*\log(NNZ))$ search.
The hypothesis is that, with sufficient optimization, this approach can provide comparable performance to a hand-implemented version of the code.

\section{Constructing a Sparse Iteration Space}\label{sec:sparseIterspace}
Omitting unnecessary iterations is key to the performance of a sparse computation. 


The first performance barrier for SparseRAJA is the representation and construction of the sparse iteration space.
While individual dimensions in a RAJA iteration space can be ranges (using \verb.RangeSegment.) or arbitrary lists (using \verb.ListSegment.), dimensions can only be combined using the cartesian product. 
This presents a problem, as scarcely any sparse iteration spaces can be represented as a cartesian product.
Another option is needed, and here, I explore two.


\subsection{Option 1: Specialized Iterators}
The leader/follower iterator approach requires no changes to the kernel policy, but is limited in the scheduling orders in can support. 
At a high level, the iterators for each loop dimension are synchronized, traversing a zipped list rather than a cartesian product. 
Because this method incorporates the synchronization through the segments themselves, it does introduce some runtime overhead.

When constructing the sparse iteration space, the outermost segment is created as a \verb.LeaderSegment. object and the inner segments are created as \verb.FollowerSegment. objects.
The inner \verb.FollowerSegment. objects store a reference to the lead segment with which they will synchronize.
Using this reference, the follower segments instantiate inner loops of length one, containing only the value in the synchronized position. 
This has the effect of compressing the multi-dimensional loop nest into a 1 dimensional loop nest traversing all the dimensions together.

Note that in this form, the approach can only support perfectly nesting schedules.
This becomes clear with an example.
Consider the following code, which accumulates the row sums of a sparse matrix into the dense vector \verb.y..:
\begin{figure}
\begin{lstlisting}
using POLICY=KernelPolicy<
  statement::For<0,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>
    >
  >
>;

auto init_lam = [=](auto i) {
  y(i) = 0.0;
}
auto accum_lam = [=](auto i, auto j) {
  y(i) += A(i,j);
}

auto i_dim = LeaderSegment(  {0,0,1,2,4,4,4,7});
auto j_dim = FollowerSegment({1,8,0,2,3,4,7,9});

kernel<POLICY>(make_tuple(i_dim,j_dim), init_lam, accum_lam);
\end{lstlisting}
\end{figure}
The correct behavior of this loop would be to zero out \verb.y(0)., then add to it \verb.A(0,1). and \verb.A(0,8)..
Next, it would zero out \verb.y(1). and add to it \verb.A(1,0)..
This process should continue, summing one value into \verb.y(2)., three values into \verb.y(4)., and finally one value into \verb.y(7)..

However, using this version of the leader/follower formulation, a different behavior emerges.
Because all iterator incrementing happens in the leader segment's loop level, the contents of \verb.y. are zeroed each time.
\verb.y(0). is zeroed, then \verb.A(0,1). is added.
Then \verb.y(0). is zeroed and \verb.A(0,8). is added.
This repeats with each point in the iteration space, constantly overwriting the output. 
This problem can be resolved, using a refinement discussed in the subsection after next.

\subsection{Option 2: Loop Flattening}

The second option, loop flattening, approaches the problem from the direction of the kernel policy rather than the iteration space objects themselves.
Here, a new policy statement type is introduced: \verb.FlatFor.. 
It functions similarly to the \verb.For. statement policy, but rather than iteration a single segment, it iterates multiple simultaneously. 

Because this approach changes the kernel policy, a template parameter, it is less amenable to runtime modifications. 
Furthermore, it more strictly encodes the data layout into the schedule, making it more costly to change the computation to use a different format.
However, it would incur less overhead during kernel execution than the Leader/Follower Iterators approach, as it avoids the code associated with traversing the length one inner loop nests.

An additional drawback of this approach is that it only supports perfect nesting for the dimensions that it flattens. 
This means that a loop nest that uses additional statements to initialize data or write temporaries back to memory either before or after the second nesting level cannot be represented using the \verb.FlatFor. approach.
Because of these drawbacks, I use a modified leader/follower iterator approach in the prototype, but an approach that combines the two may be the most effective.

\subsection{Compressed Leader/Follower Iterators}

The chosen approach refines the basic leader/follower iterator approach and lays the foundation for supporting compressed formats like CSR and CSC.

Rather than doing all incrementing within the leader iterator and having the follower iterators traverse a length one segment, the leader segment compresses its dimension in the style of the CSR row pointer, and the follower iterators traverse variable length segments based on the number of nonzeros that share the same leader iterator value.
This modified approach essentially constructs the CSR compressed dimension as part of the execution.
This approach is perfect for loops that have initialization and finalization statements, such as the summing loop nest discussed above. 


\section{Traversing Sparse Data Efficiently}\label{sec:SparseAccess}

Even with the iteration space reduced to only the necessary points, acceptable performance depends on traversing the sparse data structures efficiently without requiring a search on each access.
Here, the tradeoff is between flexibility in supporting types of computations and the performance benefits of more aggressive specialization.

\subsection{Option 1: ``Expected Next Access'' Cache}

The most flexible approach is something akin to software prefetching, based on the assumption that data will be accessed in order. 
With this approach, before an access reverts to a search of the sparse data, it checks if the current access is for the next nonzero in the View.
If so, it skips the search and immediately returns the value.
If not, it searches the View for the desired value.

While this approach incurs the cost of checking the access against the expected, it avoids the much more expensive cost of searching the entire data structure each time teh View is read or written.
Additionally, it only needs a snigle access function, avoiding the type manipulation of the other options, and supports correct execution for all kernels, regardless of data access patterns.
Listing~\ref{expectedAccessImpl} shows a possible implementation of such an access function.
\begin{figure}
\begin{lstlisting}[caption={Possible implementation fo the Expected Next Access approach to efficient data traversal.},label=expectedAccessImpl]
ElementType access(auto i0, auto i1) {
  static int expectedIdx = 0;
  if (i0 == dims[0][expectedIdx] && i1 == dims[1][expectedIdx]) {
    return values[expectedIdx++];
  }
  
  entryIndex = search(i0,i1);
  if (entryIndex == -1) {
    return 0;
  } else {
    expectedIdx = entryIndex+1;
    return values[entryIndex];
  }
}
\end{lstlisting}
\end{figure}

This approach can also be used to skip searching on accesses to coordinates with zero values.
For example, if the current access is lexicographically greater than the previous access and lexicographically less than the expected one, it can be inferred that the access should return zero. This is useful in computations that make stencil accesses.

\subsection{Option 2: Specialized Traversal Layouts}
For a certain class of kernels, where there is only one access to a sparse View, and the schedule traverses that data in order, a different approach could remove the check present in the first approach.

In this approach, each format has two implementations. 
One implementation performs a random access search, while the other traverse the data in order. 
If a programmer indicates the data will be traversed in order, or the runtime system can prove that it will, the View can be switched to the fast access format before kernel execution.

This approach has the benefit of faster access times at the cost of a smaller domain of possible kernels it could uspport. 
For example, it could not support a kernel that makes two accesses to the same View or one that makes multiple traveresals of the data, such as a matrix multiplication.

Abbreviated implementations of the formats are shown in Listing~\ref{specializedLayoutsImpl}.
\begin{figure}
\begin{lstlisting}[caption={Abbreviated format implementation for the Specialized Traversal Layout approach.},label=specializedLayoutsImpl]
class FastCOO {
  int currIdx = 0;
  \dots
  void preKernelLaunch() {
    currIdx = 0;
  }
  ElementType access(Idxs...indices) {
    return values[currIdx++];
  }
}
\end{lstlisting}
\end{figure}

\subsection{Option 3: Specialized Index Types}
The third option, like the second, uses an approach of dispatching to different access functions based on access pattern information.
Here, rather than using the View's layout type to select the access function, I use the type of the loop index values passed to the lambdas.
For example, the COO format may have two access functions, specialized for different inputs.
Listing~\ref{specializedIndexImpl} shows possible access functions fro the COO format.

This approach has the benefit of maintaining a single View layout type, avoiding the virtualization necessary to support the second approach.
This removes yet another source of overhead in the sparse access functions.
However, because it changes the type of the indexing variables, it imposes some of the same limitations as the symbolic evaluation functionality. 
Critically, all the data structures used in a kernel would need to support the different index types. 
For codes that only used dense and sparse Views, this is less of a problem.
For codes that access vectors or traditional arrays, this presents more serious issues.
Additionally, if two sparse Views are used in the same kernel, they both need to traverse their data in the efficient order.
This is because the same index type has to be used for both sparse Views.


\begin{figure}
\begin{lstlisting}[caption={Reference implementation for the Specialized Index Types approach.}, label=specializedIndexImpl]

ElemetType access(int i0, int i1) {
  return searchAccess(i0,i1);
}
int fastIdx = 0;
ElementType access(FastIdx i0, FastIdx i1) {
  return values[fastIdx++];
}
\end{lstlisting}
\end{figure}

\subsection{Striking a Balance}
While the latter two options offer the potential for better performance than the first, it comes at a steep price of applicability.
For this reason, I use the expected next access approach in the prototype.
Certain computations present a challenge for all three approaches, such as the multiplication of a sparse matrix with its transpose.
Support for efficient traversal in such a computation is a direction for future research, and likely relies on maintaining multiple copies of the data structure, stored in different orders.
Such an approach could also mantain multiple expected access checks, one for each of the two storage directions.

\section{Prototype Implementation}

I implemented the approaches discussed in the previous two sections into a prototype for sparse computation support within RAJA.~
Here, I discuss the interface and algorithms for constructing sparse data structures, iteration spaces, and computations.
% Constraints
% \begin{itemize}
% 	\item Conditional statements within loop bodies must not contain View accesses in their conditional expression.
% 	\item View indexing expressions must be lone iterators rather than affine expressions of the iterators, as in previous chapters.
% 	\item All writes to sparse Views must be updates, not insertions of new nonzeros.
% \end{itemize}

\subsection{Sparse Data Containers}

With the prototype's limitation to coordinate storage, two functions support the creation of sparse views: \verb.make_sparse_view. and \verb.make_permuted_sparse_view..
The former is a wrapper of the latter, generating a SparseView with the identity permutation.
For an $N$ dimensional SparseView, there are $N+2$ parameters to \verb.make_permuted_sparse_view..
The first $N$ parameters are vectors containing the index values for each dimension. 
This means that for a 2 dimensional SparseView, the first two arguments are the row and column indices of the entries.
The $N+1th$ parameter is a vector containing the entries themselves. 
Finally, the last parameter is the permutation vector for the SparseView. 
The idea of the permutation vector is that it changes how the entries of the view are sorted, but not how they are referenced / indexed.

Consider a sparse view containing the following entries, presented here unordered:
\begin{lstlisting}
DIM0: 0 1 2 1 0 2
DIM1: 1 1 0 2 2 0
DIM2: 1 0 2 1 0 0
VAL : A B C D E F 
\end{lstlisting}
If these entries are used to construct the standard SparseView, they will be reordered and stored as follows:
\begin{lstlisting}
DIM0: 0 0 1 1 2 2
DIM1: 1 2 1 2 0 0
DIM2: 1 0 0 1 0 2
VAL : A E B D F C
\end{lstlisting}
If the SparseView is constructed with the permutation vector $(2,0,1)$, they will be stored as:
\begin{lstlisting}
DIM0: 0 1 2 0 1 2
DIM1: 2 1 0 1 2 0
DIM2: 0 0 0 1 1 2
VAL : E B F A D C
\end{lstlisting}
Note that the list of dimensions is not permuted, only the order the entries are sorted. 
What this scheme means is that no matter the permutation, the access \verb.view(0,1,1). will always return \verb.A., even if its location in the list of entries changes.

The nonzero pattern of the SparseView data type is a read-only feature in the prototype.
This is not an inherent limitation, but additional considerations must be taken into account when designing mutable sparse data structures.
For example, because the iteration space of a sparse computation is based on the nonzero structure of the SparseView used in it, inserting new nonzeros into a SparseView during a computation could change the computation's iteration space as it is executing.
Additionally, the cost of inserting elements one at a time can be quite high. 
Thus, it is usually preferable to create a buffer of elements to insert and update the data structure all at once.
This buffer can take the form of a hash table which is emptied into the SparseView periodically.
With this in mind, it is possible to update the values of existing nonzero values within SparseViews, as this does not require inserting new elements into the data structure.

The SparseView class is templated by three values: the element type, the number of dimensions, and the type of the Format.
\verb.make_sparse_format. has an optional template parameter for choosing different formats, defaulting to coordinate storage.
The SparseView class wraps the templated sparse format type and manages a symbolic evaluation itself.
Most of its methods directly forward to calls of the format implementation class.
A programmer can easily create a new sparse format by creating an implementation class that implements a small collection of functions.
Most important is the call operator, but also necessary are functions for accessing individual dimension index values, the number of nonzero entries, and diagnostic functions for examining the expected access cache hit rates.

\subsection{Sparse Iteration Spaces}
The implemented algorithm for automatically constructing the sparse iteration space from the dense iteration space and a sparse data access addresses the common case.
It assumes the iteration space dimensionality and the data space dimensionality are equal, and is based on an access to the sparse data that uses each loop iterator once.

The idea of the algorithm is to construct the sparse iteration space out of the dimensions of the SparseView. 
First, the dimensions of the iteration space are matched to the dimensions of the SparseView based on the access information gathered from the symbolic evaluation.
For example, the accesses \verb.A(i,j). and \verb.A(j,i). match the first dimension of the SparseView to the first and second dimensions of the iteration space, respectively.
Second, the lead dimension, traversed by the outermost \verb.For. statement, is constructed using the relevant SparseView dimension.
This requires that the SparseView is sorted by this dimension on the first level.
Once this is complete, the follow dimensions are constructed for the remaining dimensions of the SparseView.
Listing~\ref{sparsifyAlg} shows a pseudo-code implementation of the algorithm.
\todo{update algorithM}.

\begin{figure}
\begin{lstlisting}[caption={Abbreviated algorithm for sparsifying a dense iteration space.}, label=sparsifyAlg]
auto sparsify(IterationSpace denseSpace, SparseAccess access) {
  auto q = invert(access.orderPermutation);
  auto view = access.accessedView;

  auto sparseRect = [];
  auto leadDimension = SparseSegmentLead(view, q[0]);
  sparseRect.push_back(leadDimension);
  for(int i = 1; i < view.numDims; i++) {
    auto dim = SparseSegmentFollow(view, q[i], &leadDimension);
    sparseRect.push_back(dim);
  }
  return IterationSpace(sparseRect, denseSpace.constraints);
}
\end{lstlisting}
\end{figure}

\subsection{Sparse Kernel Objects}

The automatic construction of a sparse iteration space is surfaced to the user through the \verb.make_sparse_kernel. function.
An extension of the existing \verb.make_kernel. function, the sparse variant includes two extra parameters (one optional, one required) used to construct the sparse iteration space.
First is the required runtime parameter for the sparse View that the iteration space should be constructed around.
This parameter comes after the dense iteration space and before the lambdas for the loop bodies.
Second is an optional template index parameter, specifying which of the lambdas should be evaluated symbolically to gather the access information necessary for creating the new iteration space.
An abbreviated implementation is shown in Listing~\ref{makeSparseKernelAlg}.

When called, \verb.make_sparse_kernel. starts by symbolically evaluating the specified lambda.
This collects all access information, for both sparse and dense Views.
The next step isolates the accesses to the sparse View guiding the construction by a standard search.
This access, the kernel policy, and the dense iteration space are then used to construct the sparse iteration space.
The final step is to return a KernelWrapper that will execute the computation over the newly constructed sparse iteration space.

\begin{figure}
\begin{lstlisting}[caption={Abbreviated implementation of the function for creating a computation that automatically constructs the sparse iteration space.}, label=makeSparseKernelAlg]
template <typename KernelPolicy, idx_t SymExecLamIdx=0>
auto make_sparse_kernel(auto denseSegs, auto sparseView, auto loopBodyTuple) {
  auto symExecLambda = get<SymExecLamIdx>(loopBodyTuple);
  auto allAccesses = symbolically_evaluate(symExecLambda);
  auto sparseAccess = findAccessTo(sparseView, allAccesses);

  auto sparseSegs = make_sparse_iteration_space<KernelPolicy>(denseSegs, 
  sparseAccess);

  return make_kernel<KernelPolicy>(sparseSegs, loopBodyTuple);
}
\end{lstlisting}
\end{figure}

Alternatively, the programmer can construct the sparse iteration space themselves, then use the standard \verb.make_kernel. to generate the computation over the sparse iteration space.

\section{Evaluation}\label{sec:sparseEval}
To evaluate the prototype, I compare the performance of different versions of three benchmarks: sparse matrix vector multiplication (SpMV), Gauss-Seidel iteration (GauSei), and incomplete Cholesky factorization (InCholFact).
The first version, \dense, implements the computation on dense data. 
The second version, \specialized, is specialized for a particular sparse format by hand. 
The third version, \sparseraja, implements the computation using the prototype support described above.
In terms of representation, the expectation is that the \dense{} and \sparseraja{} versions of the code will look similar, both varying significantly from the format-specific implementation of the \specialized{} version.
In terms of performance, the \dense{} version is expected to be the outlier, as it executes many more iterations than the \sparseraja{} and \specialized{} versions.

The evaluation process here is iterative, progressing through a loop of running the evaluation, profiling using hpctoolkit~\cite{adhianto2010hpctoolkit}, identifying potential optimizations, and implementing them. 
This is in service of evaluating the overall question of the feasibility of acheiving comparable performance to the hand-specialized variants.





\subsection{Benchmark 1: SpMV}
While a relatively simple computation on its own, sparse matrix vector multiplication (SpMV) is a foundational building block for sparse computations.
The computation has two pieces of input data: a sparse matrix \verb.A. and a dense vector \verb.x.. 
Each element of the single output vector \verb.y. is the dot product of the corresponding row of \verb.A. with the whole vector \verb.x..
Listings~\ref{DenseMV},~\ref{SpecializedMV}, and~\ref{SparseRAJAMV} show the reference implementations for the three versions of the computation.


\begin{figure}
\begin{lstlisting}[caption={RAJA implementation of dense matrix vector multiplication.},label=DenseMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
DenseView<2> A(Ni,Nj);

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::Lambda<0>
    >
  >
>;

auto seg1 = RangeSegment(0,Ni);
auto seg2 = RangeSegment(0,Nj);
auto segs = make_tuple(seg1, seg2);

auto lam = [&](auto i, auto j) {
  y(i) += A(i,j) * x(j);
};

auto knl = make_kernel<POLICY>(segs, lam);
knl();
\end{lstlisting}
\end{figure}
\begin{figure}
\begin{lstlisting}[caption={RAJA implementation of sparse matrix vector multiplication, specialized for COO storage.},label=SpecializedMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
DenseView<1> A_cols(NumNonZeros);
DenseView<1> A_rows(NumNonZeros);
DenseView<1> A_vals(NumNonZeros);

auto seg = RangeSegment(0,NumNonZeros);

auto lam = [&](auto idx) {
  auto i = A_rows(idx);
  auto j = A_cols(idx);
  y(i) += A_vals(idx) * x(j);
};

auto knl = make_forall<loop_exec>(seg, lam);
knl();
\end{lstlisting}
\end{figure}
\begin{figure}
\begin{lstlisting}[caption={Implementation of SpMV using the SparseRAJA prototype},label=SparseRAJAMV]
DenseView<1> x(Nj);
DenseView<1> y(Ni);
SparseView<2> A(Ni,Nj);

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::For<1,loop_exec,
      statement::Lambda<0>
    >
  >
>;

auto seg1 = RangeSegment(0,Ni);
auto seg2 = RangeSegment(0,Nj);
auto dense_segs = make_tuple(seg1, seg2);

auto lam = [&](auto i, auto j) {
  y(i) += A(i,j) * x(j);
}

auto knl = make_sparse_kernel<POLICY>(dense_segs, A, lam);
  
knl();
\end{lstlisting}
\end{figure}




\subsection{Benchmark 2: Gauss-Seidel Iteration}

The second kernel, Gauss-Seidel iterative solve, is a well-known kernel for approximating the solution to a linear system.
The problem of solving a linear system is thus: given a coefficient matrix $A$ and a right-hand side vector $b$, find a vector $x$ such that $Ax=b$.
The Gauss-Seidel method does this by starting with an initial guess and successively refining it to closer and closer approximations.
This process is repeated until a desired level of accuracy is reached.

While the kernel itself is applied iteratively to refine the approximation, we focus here on the operations of the iterations internal to the kernel.
An imperfectly nested, two-dimensional loop nest, GauSei updates each element of the solution vector $x$ in sequence.
First, the dot product of a row of $A$ and the current approximation is accumulated in a temporary variable.
Note that if the approximation is exactly correct, this value will be equal to the corresponding entry of $b$. 
The difference between the temporary and the right-hand side is then used to update the approximation, and the process repeats.

Gauss-Seidel is a tricky kernel because of its data dependences.
The results of earlier iterations change values used in subsequent ones, meaning that the order of the iterations cannot be changed arbitrarily. 
For this reason, GauSei cannot be represented as tensor algebraic expressions, placing it outside TACO's space of expressible computations~\cite{}.

Listings~\ref{DenseGauSei},~\ref{SpecializedGauSei}, and~\ref{SparseRAJAGauSei} show the three reference implementations of the GauSei kernel.
Because of the significant variations between the three implementations, I also show a C-like reference implementation in Listing~\ref{CppGauSei}.

One such variation appears in the \specialized{} version. 
Because specializing the implementation for the COO format flattens the iteration space from two dimensions to one, guard statements must be inserted to check for changes in rows. 
Furthermore, it also requires pulling part of the final iteration out of the loop.

\begin{figure}
\begin{lstlisting}[caption={C-like version of Gauss-Seidel iteration},label=CppGauSei]
View<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

while(!has_converged()) {
  for(int i = 0; i < N; i++) {
    temp = 0.0;
    for(int j = 0; j < N; j++) {
      if (j != i) {
        temp += A(i,j) * x(j);
      }
    }
    x(i) = (b(i) - temp) / A(i,i);
  }
}
\end{lstlisting}
\end{figure}

\begin{figure}
\begin{lstlisting}[caption={\dense{} version of Gauss-Seidel iteration},label=DenseGauSei]
View<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>,
    >,
    statement::Lambda<2>
  >
>;

auto lam1 = [&](auto i) {
  temp = 0.0;
};
auto lam2 = [&](auto i, auto j) {
  if (j != i) {
    temp += A(i,j) * x(j);
  }
};
auto lam3 = [&](auto i) {
  x(i) = (b(i) - temp) / A(i,i);
}

auto seg1 = RangeSegment(0,N);
auto seg2 = RangeSegment(0,N);
auto segs = make_tuple(seg1, seg2);

auto knl = make_kernel<POLICY>(segs, lam1, lam2, lam3);

while (!has_converged()) {
  knl();
}
\end{lstlisting}
\end{figure}

\begin{figure}
\begin{lstlisting}[caption={\specialized{} version of Gauss-Seidel iteration},label=SpecializedGauSei]
View<2> A_rows(NNZ);
View<2> A_cols(NNZ);
View<2> A_vals(NNZ);
View<1> b(N);
View<1> x(N) = initial_guess;

while (!has_converged()) {
  int prev_i = 0;
  double temp = 0.0;
  for(int idx = 0; idx < NNZ; idx++) {
    int i = A_rows(idx);
    int j = A_cols(idx);
    double v = A_vals(idx);

    if (i != prev_i) {
      double prev_diagonal = find(prev_i, prev_i, A_rows, A_cols, A_vals);
      x(prev_i) = (b(prev_i) - temp) / prev_diagonal;
      temp = 0.0;
      prev_i = i;
    }
    if (j != i) {
      temp += v * x(j);
    } 
  }
  double prev_diagonal = find(prev_i, prev_i, A_rows, A_cols, A_vals);
  x(prev_i) = (b(prev_i) - temp) / prev_diagonal;
}
\end{lstlisting}
\end{figure}


\begin{figure}
\begin{lstlisting}[caption={\sparseraja{} version of Gauss-Seidel iteration},label=SparseRAJAGauSei]
SparseView<2> A(N,N);
View<1> b(N);
View<1> x(N) = initial_guess;
double temp;

using POLICY = KernelPolicy<
  statement::For<0,loop_exec,
    statement::Lambda<0>,
    statement::For<1,loop_exec,
      statement::Lambda<1>
    >,
    statement::Lambda<2>
  >
>;

auto lam1 = [&](auto i) {
  temp = 0.0;
};
auto lam2 = [&](auto i, auto j) {
  if (j != i) {
    temp += A(i,j) * x(j);
  }
};
auto lam3 = [&](auto i) {
  x(i) = (b(i) - temp) / A(i,i);
};

auto seg1 = RangeSegment(0,N);
auto seg2 = RangeSegment(0,N);
auto segs = make_tuple(seg1, seg2);

auto knl = make_sparse_kernel<POLICY, 1>(segs, A, lam1, lam2, lam3);

while (!has_converged()) {
  knl();
}
\end{lstlisting}
\end{figure}

\subsection{Benchmark 3: Incomplete Cholesky Factorization}
\begin{figure}
\begin{lstlisting}[caption={C++ reference implementation of incomplete Cholesky factorization.},label=CppInCholFact]

View<2> A(N,N);   

for(i0 = 0; i0 < N; i0++) {
  A(i0,i0) = sqrt(A(i0,i0));
  for(i1 = i0+1; i1 < N; i1++) {
    if (A(i1,i0) != 0) {
      A(i1,i0) /= A(i0,i0);
    }
  }
  for(i1 = i0+1, i1 < N; i1++) {
    for(i2 = i1; i2 < N; i2++) {
      if (A(i2,i1) != 0) {
        A(i2,i1) -= A(i2,i0) * A(i1,i0);
      }
    }
  }
}

for(i0 = 0; i0 < N; i0++) {
  for(i1 = i0+1; i1 < N; i1++) {
    A(i0,i1) = 0;
  }
}
\end{lstlisting}
\end{figure}

\todo{introduce what it does}

\todo{introduce data requirements}

\todo{discuss any notable characteristics.}

\todo{reference implementations}


\subsection{Performance Results}

\subsubsection{SpMV}
\begin{figure}
\includegraphics[width=0.5\textwidth]{SpMV_lines_perf.pdf}
\caption{Matrix vector multiplication execution times for different variants and sparse matrix densities. Each subplot charts a different dimension length. Both x and y are log scale. Lower is better.}\label{SpMVPerformance}
\end{figure}
Figure~\ref{SpMVPerformance} shows the performance evaluation results for the \SpMV{} kernel. 
The three lines represent the different variants.

For each subplot charting the results of evaluation for one dimension length, the \dense{} variant shows constant execution time across densities.
This is because it performs all iterations, even if the value in the matrix is 0.
Both the \sparseraja{} and \specialized{} variants show consistent linear scaling with density and size. 


% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -d 0.5 -d 0.1 -d 0.01 -d 0.001 --spmv -o results3.csv --dense --specialized --sparseRAJA
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -d 0.3 -d 0.03 -d 0.2 --spmv -o results3.csv --dense --specialized --sparseRAJA --append 
% ./run.sh -s 384 -d 0.5 -d 0.1 -d 0.01 -d 0.001 -d 0.3 -d 0.03 -d 0.2 --spmv -o results3.csv --dense --specialized --sparseRAJA --append
% ./run.sh -s 512 -d 0.1 -d 0.01 -d 0.001 -d 0.3 -d 0.03 -d 0.2 --spmv -o results3.csv --specialized --sparseRAJA --append
% ./run.sh -s 512 -d 0.5  --spmv -o results3.csv --dense --append
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -d 1.0 -d 0.8 --spmv -o results3.csv --specialized --append
With the first version the \sparseraja{} variant shows a geometric mean speedup of 0.103, just under a 10x slowdown.
Analysis with hpctoolkit uncovered an expensive vector allocation within the access function.
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 -d 0.3 -d 0.1 -d 0.05 -d 0.025 -d 0.01 --spmv -o results4.csv --specialized --sparseRAJA
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 --spmv -o results4.csv --dense --append 
Using a fixed size \verb.std::array. triples relative performance with a 0.282 geometric mean speedup, just under a 4x slowdown.
More optimization passes will be necessary to continue improving performance.
%hpcrun ./build/bin/sparseEval.exe 0 0 1 1 0 0 800 0.2
%hpcrun ./build/bin/sparseEval.exe 0 0 1 1 0 0 800 0.8
%hpcstruct -Isrc/+ build/bin/sparseEval.exe
%hpcprof -Isrc/+ -SsparseEval.exe.hpcstruct hpctoolkit-sparseEval.exe-measurements

% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 -d 0.3 -d 0.1 -d 0.05 -d 0.025 -d 0.01 --spmv -o results5.csv --specialized --sparseRAJA
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 --spmv -o results5.csv --dense --append 

%./run.sh -s 1000 -d 0.8 --spmv --sparseRAJA --append --profile -o profiling3


% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 -d 0.3 -d 0.1 -d 0.05 -d 0.025 -d 0.01 --spmv -o results6.csv --specialized --sparseRAJA
% ./run.sh -s 64 -s 128 -s 192 -s 212 -s 256 -s 384 -s 512 -d 0.5 --spmv -o results6.csv --dense --append 
One unexpected result is that even with a density of 1, indicating a completely dense array, the specialized COO variant still outperforms the dense View. 
This may be caused by specialized version doing a simpler 1 dimensional index calculation.



\subsubsection{GauSei}
\begin{figure}
  \includegraphics[width=\textwidth]{GauSei_lines_perf_COO.pdf}
  \caption{Gauss-Seidel iteration execution times for different variants and sparse matrix densities. Each subplot charts a different dimension length. Both x and y are log scale. Lower is better. The sparseRAJA variant uses standard coordinate storage.}\label{GauSeiPerfCOO}
\end{figure}
\begin{figure}
\includegraphics[width=\textwidth]{GauSei_ratios_perf_COO.pdf}
\caption{Ratio of \sparseraja{} variant execution time to \specialized{} variant execution time. Each subplot charts a different dimension length. Lower is better. Values greater than 1 indicate that the \sparseraja{} variant is slower. The \sparseraja{} variant uses standard coordinate storage.}\label{GauSeiRatioCOO}
\end{figure}

\begin{figure}
\includegraphics[width=\textwidth]{GauSei_lines_perf_DIAG.pdf}
\caption{Gauss-Seidel iteration execution times for different variants and sparse matrix densities. Each subplot charts a different dimension length. Both x and y are log scale. Lower is better. The \sparseraja{} variant uses the prototype DIAG format.}\label{GauSeiPerfDIAG}
\end{figure}
\begin{figure}
\includegraphics[width=\textwidth]{GauSei_ratios_perf_DIAG.pdf}
\caption{Ratio of \sparseraja{} variant execution time to \specialized{} variant execution time. Each subplot charts a different dimension length. Lower is better. Values greater than 1 indicate that the \sparseraja{} variant is slower. The \sparseraja{} variant uses standard coordinate storage.}\label{GauSeiRatioDIAG}
\end{figure}
Figure~\ref{GauSeiPerfCOO} shows the initial performance of the SparseRAJA implementation using the COO storage format.
Figure~\ref{GauSeiRatioCOO} shows the ratio of the SparseRAJA variant execution time to the specialized variant execution time.
The geometric mean speedup of the SparseRAJA version relative to the specialized version is $0.228$, between a 4 and 5x slowdown. 
From the early profiling rounds of the \GauSei{} kernel, nearly 90\% of the execution time is spent in the SparseView's search-based random access function.
This is caused by the comparatively low expected access cache hit rate, driven by the irregular access patterns in the kernel.
First, each of the diagonal entries is skipped during the execution of the inner loop nest.
After each diagonal iteration, where no access is made because the conditional is false, the expected access is still the diagonal entry. 
Thus, the following iteration will access the entry after the diagonal and have to search.
Second, each diagonal is accessed after the row is processed in the finalizing statement.
This causes two misses, one when the finalizing statement executes and the access to the diagonal entry is made, then another on the first inner iteration of the next row, attempting to access the first entry of the row.
Barring the occasional circumstance where the diagonal is the last or only value in the row, there are three misses for each row in the input matrix.

Here we encounter a situation where a different data format would be beneficial.
For example, a format that additionally stores a vector of the diagonal entries separately from the other entries.
On an access, if the access is for a diagonal, it indexes directly into the vector, otherwise following the usual pattern of prefetching and searching.
Figure~\ref{GauSeiPerfDIAG} shows the perforamnce of a variant using this DIAG storage format instead of the general COO format compared to the specialized hand-implemented variant.
Here, the geometric means speedup is $0.182$, between a 5 and 6x slowdown, and slower than the coordinate storage variant. 
This may be caused by the additional overhead of checking each if each access is to the diagonal.


\section{Conclusion}

This chapter explored incorporating support for sparse computations and data formats into the RAJA performance portability library.
By treating the sparsity of the data as an independent component of the computation's specification, the approach enables concise and format-independent programming. 
However, the overhead of maintaining and updating the necessary data structures for kernel execution, especially updating the sparse iterative values, caused performance to suffer.
While this approach may be feasible as a foundation for introducing schedule and data transformations for sparse computations, more work is needed to bring the performance of the system within the range of hand-implemented versions.







% \subsection{Computation Interface}

% The driving concern for the interface is that the details of which sparse formats the Views are stored in should be abstracted out of the computation description as much as possible. 
% This means that the description of a sparse computation should look very similar to that of a dense computation. 

% I introduce a new computation wrapper type, \verb.SparseKernelWrapper. to visually indicate that the computation should consider the sparsity of the data. 
% Like the original \verb.KernelWrapper. type, I also introduce a \verb.make_sparse_kernel. function for creating sparse computation objects. 



% \begin{figure}
% \begin{lstlisting}

% \end{lstlisting}
% \end{figure}



% \subsection{Sparsifying the Iteration Space}

% Once the computation object has been created, the sparsity of its data must be used to reduce the iteration space to only the points where nonzero datapoints exist.
% My approach proceeds in two phases: a symbolic representation phase and a execution phase. 


% \begin{figure}
% \begin{lstlisting}[caption={Algorithm to sparsify iteration space based on access to SparseView}]
% haveCompressed = false;
% compressedDim = -1;
% for nest in nesting:
% 	if nest not in access:
% 		sparseSegs[nest] = segs[nest];
% 	else if haveCompressed:
% 		idx = access.indexOf(nest);
% 	sparseSegs[nest] = segs[nest] & view.dense_by(idx, compressedDim);
% 	else:
% 		idx = access.indexOf(nest);
% 		sparseSegs[nest] = segs[nest] & view.compressed(idx);
% 		haveCompressed = true;
% 		compressedDim = idx;

% return sparseSegs;
% \end{lstlisting}
% \end{figure}


% \subsection{Efficient Iteration Through Data}


% \subsection{Permuted Coordinate Sparse Views}


% The interaction between RAJA kernel policy execution and the permuted data structure creates a challenge. 
% I turn now to a short investigation of RAJA kernel policies to elucidate this challenge.

% \subsection{Kernel Policies for Sparse Computations}

% I begin this investigation with the following two dimensional kernel:
% \begin{lstlisting}
% using POLICY = KernelPolicy<
%   statement::For<0,seq_exec,
%     statement::For<1,seq_exec,
%       statement::Lambda<0>
%     >
%   >
% >;

% auto segments = make_tuple(RangeSegment(0,2), RangeSegment(3,5));

% kernel<POLICY>(segments, [=](auto i0, auto i1) {
%   std::cout << i0 << "," << i1 << "  ";
% });
% \end{lstlisting}
% From this kernel, we would expect the output to be \verb.0,3  0,4  1,3  1,4..

% Next, consider the same kernel with the following slightly modified kernel policy:
% \begin{lstlisting}
% using POLICY = KernelPolicy<
%   statement::For<1,seq_exec,
%     statement::For<0,seq_exec,
%       statement::Lambda<0>
%     >
%   >
% >;
% \end{lstlisting}
% With this policy, the outer for loop will increment the second segment and the inner loop will increment the first.
% Thus, the expected output would be \verb.0,3  1,3  0,4  1,4..

% Finally, consider a different modification to the kernel policy:
% \begin{lstlisting}
% using POLICY = KernelPolicy<
%   statement::For<0,loop_exec,
%     statement::For<1,loop_exec,
%       statement::Lambda<0>
%     >
%   >
% >;
% \end{lstlisting}
% Here, the loop-level execution policies have changed from \verb.seq_exec. to \verb.loop_exec..
% And while this has changed, we still would expect the output to be \verb.0,3  0,4  1,3  1,4..
% So what has changed? 
% Something quite subtle about the semantics. 
% The \verb.seq_exec. policy demands \enquote{strictly sequential execution,} whereas \verb.loop_exec. \enquote{allow[s] the compiler to generate any optimizations that its heuristics deem beneficial}~\cite{rajadocs}.

% Now, why is this relevant? 
% It is relevant because these concepts must be mapped to sparse computation in a way that is intuitive but still enables efficient execution on the backend.
% So the question here is: what constraints on the sparse schedule are imposed by the use of policies with either \verb.seq_exec. or \verb.loop_exec.?

% One thing is somewhat clear: regardless of the loop-level execution policy, kernel execution should be implemented as two nested for loops. 
% Further, the for loops should traverse the dimensions indicated in the policy. 
% This means the difference between \verb.loop_exec. and \verb.seq_exec. is constrained to an individual loop level. 

% Once more, why is this relevant? 
% The relevance comes from the the task of sparsifying an iteration space when the traversal order of the iteration space does not match the storage order of the sparse data.
% If the iteration space traversal order is a strict constraint, then there are two options.
% Either we reorder the sparse data to match the traversal order, or we perform a \enquote{trivial sparsification,} returning the original dense iteration space.

% \subsection{A Constraint of Idiomatic RAJA}

% The challenge of the previous subsection uncovers a constraint imposed by the RAJA library's design.
% RAJA's execution strategy is based on the enumeration of a cross product. 
% Every combination of values in the segments is visited.
% For a sparse iteration space, this approach fails.
% Rather than enumerating a cross product, a sparse computation must iterate over each dimension simultaneously. 
% The values of $j$ when $i=0$ are different from the values of $j$ when $i=1$. 

% The core of the problem here is that the inner dimensions of a loop must not be static. 
% They must be able to change as the outer iterators change.

% \subsection{Another Problematic Example}

% Consider the following kernel for a square, sparse matrix \verb.A. in the unpermuted COO format:
% \begin{lstlisting}

% using POLICY = KernelPolicy<
%   statement::For<0, loop_exec,
%     statement::For<1, loop_exec,
%       statement::Lambda<0>
%     >
%   >
% >;
% auto segments = make_tuple(seg, seg);
% auto lam = [&](auto i, auto j) {
%   z(i) += A(i,j) * y(j);
% }

% kernel<POLICY>(segments, lam);
% \end{lstlisting}
% In this computation, we have a nesting order $(0,1)$, a layout order $(0,1)$, and an access order $(0,1)$. 
% We can sparsify the iteration space without changing the layout.

% Now, what if we were to change the access order? 
% \begin{lstlisting}
% auto lam2 = [&](auto i, auto j) {
%   z(i) += A(j,i) * y(j);
% }
% \end{lstlisting}
% Now, the access order has changed from $(0,1)$ to $(1,0)$. 
% The $(i,j)$th iteration is no longer accessing the $(i,j)$th element of \verb.A. 
% When we sparsify an iteration space, we must maintain all iterations where a nonzero element is accessed. But we must remove the unnecessary iterations without reordering the remaining.
% So in this case, we have the following iteration space ${[i,j] | A[j,i] != 0}$
% Before considering how it is to be calculated, we can observe that for efficient iteration, the data in \verb.A. must be sorted in the order $(1,0)$. 
% This is because the inner loop is indexing the first dimension of \verb.A. and the outer loop is indexing the second dimension. 

% Changes to the layout order do not change the semantics. Changes to the access order and nesting order do change the semantics.

% \subsection{Sparsifying the Iteration Space}

% We begin with the case of an iteration space and square view with equal dimensionality.
% Let the iteration space be $I = \{[i_0,i_1,...,i_n] | C\}$ for some constraints $C$.
% We seek to sparsify based on an access $A(i_{p(0)},i_{p(1)},...i_{p(n)})$ for a permutation $p$.
% This is equivalent to calculating the set $I_s = \{[i_0,i_1,...,i_n] | C \land A(i_{p(0)},i_{p(1)},...i_{p(n)}) \neq 0\}$.

% Let $E_A$ indicate the indices of the nonzeros entries of $A$. 
% Formally, $E_A = \{[i_0,i_1,...,i_n] | A(i_0,i_1,...,i_n) \neq 0\}$.
% Claim: for the identity permutation $p$, $E_A = I_s$.

% Proof: => 
% consider $e = [e_0,e_1,...,e_n] \in E_A$. 
% Because it is in $E_A$, we have $A(e) \neq 0$.
% Thus, if $e$ satisfies the constraints $C$, the $e$ is an element of $I_s$.
% Square view and iteration space, so it must.

% Proof: <=
% Consider $i$ in $I_s$. 
% We thus have $A[p(i)] \neq 0$.
% Because $p$ is the identity permutation, we have $p(i) = i$, so $A[i] \neq 0$, so $i \in E_A$.

% Next, let's turn to an arbitrary permutation $p$. 
% Again let $q$ be the inverse permutation of $p$. 
% Claim: $q(E_A) = I_s$.

% Proof: => 
% consider $e = [e_0,e_1,...,e_n] \in q(E_A)$.
% If we apply the permutation $p$, we have $p(e) \in p(q(E_A))$.
% Thus, $[e_{p(0)},e_{p(1)},...,e_{p(n)}] \in p(q(E_A)) = E_A$, as $p$ and $q$ resolve to the identity permutation.
% Then, by the definition of $E_A$, we have $A(e_{p(0)},e_{p(1)},...,e_{p(n)}) \neq 0$. 
% Thus, if $p(e)$ satisfies constraints $C$, $p(e) \in I_s$. 

% Proof: <=
% consider $i = [i_0,i_1,...,i_n] \in I_s$. 
% By the definition of $I_s$, we have $A(i_{p(0)},i_{p(1)},...,i_{p(n)}) \neq 0$.
% This means that $p(i) \in E_A$.
% Finally, applying the permutation $q$ gives $q(p(i)) \in q(E_A)$, or $i \in q(E_A)$.

% Let's do an example to make this more concrete.
% Three dimensional iteration space $I = [0,N]^3$.
% Access to sparse data $A(i_2,i_0,i_1)$. 
% So $p=(2,0,1)$.
% The inverse of this permutation is $q=(1,2,0)$.
% We're looking for the set $I_s = \{[i_0,i_1,i_2] | A(i_{p(0)},i_{p(1)},i_{p(2)}) \neq 0\}$. 
% Simplified with the definition of $p$, $I_s = \{ [i_0,i_1,i_2] | A(i_2,i_0,i_1) \neq 0\}$.

% Say that $A$ has the following data:
% \begin{lstlisting}
% dim0 = {0,0,0,1,1,2,2};
% dim1 = {1,2,2,1,2,0,0};
% dim2 = {0,0,2,0,1,1,2};
%    v = {1,2,3,4,5,6,7};
% \end{lstlisting}
% Consider the data point at $(0,1,0)$ holding value $1$. 
% On iteration $(1,0,0)$, the access made will be to $A(0,1,0)$.
% On iteration $(0,1,2)$ the access will be made to $A(2,0,1)$.
% So to go from iteration to access, we apply $p$. 
% To go from access to iteration, we apply $q$.
% Since we want to calculate the iteration space points that access data in $A$, we want to apply $q$ to the data space of $A$.

% While the nesting order of a kernel changes the schedule of the execution, it does not change which points are actually in the iteration space.
% Thus, the procedure of applying the inverse permutation of the access order to the data space will produce the sparsified iteration space, which can then be scheduled using the nesting order.

% With the case of square, size-matched iteration and data spaces, let's expand to the case of a nonsquare iteration and data spaces.
% For a concrete example, let's consider the iteration space $I = \{[i_0,i_1,i_2] | 0 \leq i_0 \leq N_0 \land i_0 \leq i_1 \leq N_1 \land i_0 \leq i_2 \leq i_1 \}$.
% Let's sparsify this space based on the access $A(i_2,i_1,i_0)$. 
% The access permutation $p=(2,1,0)$, and its inverse is the same.
% The set we want to calculate is $I_s = \{[i_0,i_1,i_2] | 0 \leq i_0 \leq N_0 \land i_0 \leq i_1 \leq N_1 \land i_0 \leq i_2 \leq i_1 \land A(i_2,i_1,i_0) \neq 0 \}$.

% We calculate this in parts. 
% First, we identify the iteration space points that access a nonzero. 
% Then, we apply the original constraints on the iteration space. 

% At this point, calculating the sparsified iteration space proceeds with the following algorithm:
% \begin{lstlisting}
% auto sparsify_equal_dims(IterationSpace denseSpace, SparseAccess access) {
%   auto q = invert(access.orderPermutation);
%   auto view = access.accessedView;
  
%   auto sparseRect = [];
%   auto leadDimension = SparseSegmentLead(view, q[0]);
%   sparseRect.push_back(leadDimension);
%   for(int i = 1; i < view.numDims; i++) {
%     auto dim = SparseSegmentFollow(view, q[i], &leadDimension);
%     sparseRect.push_back(dim);
%   }
%   return IterationSpace(sparseRect, denseSpace.constraints);
% }
% \end{lstlisting}
% Of course, this algorithm sidesteps the question of how the original constraints are applied to the sparsified iteration space.
% But that is a problem to be addressed in the discussion of the implementation.
% The important piece here is the general process. 
% Invert the function that takes us from the iteration space to the data space, then use that function to construct an iteration space that only contains points that access the nonzeros.

% Thus far, we have only considered the case where $dims(A) = dims(I)$.
% This leaves two more cases to consider. 
% We begin with the case where $dims(I) > dims(A)$. 
% Such a situation arises in computations like matrix multiplication.
% Here, the abstraction of the access as a permutation begins to break down. 
% For example, consider the case of $I=[0,N]^3$ and access $A(i_0,i_2)$.
% The set we want to calculate is $I_s = \{[i_0,i_1,i_2] | A(i_0,i_2) \neq 0 \land 0 \leq i_0 \leq N \land 0 \leq i_1 \leq N \land 0 \leq i_2 \leq N\}$.

% A helpful observation: changes to indices that do not appear in the access do not affect whether the iteration accesses a nonzero.
% Thus, we can temporarily set aside those dimensions.
% So we want to calculate $I\prime_s = \{[j_0,j_1] | A(j_0,j_1) \neq 0\}$, which we do using the algorithm shown above.
% Finally, we bring back the invariant dimensions, giving us $I_s = \{[i_0,i_1,i_2] | [i_0,i_2] \in I\prime_s \land \land 0 \leq i_0 \leq N \land 0 \leq i_1 \leq N \land 0 \leq i_2 \leq N\}$

% So the algorithm here becomes:
% \begin{lstlisting}
% auto sparsify_i_gt_a(IterationSpace denseSpace, SparseAccess access) {
%   variantDims = [idx for idx in denseSpace.indices if idx in access.indices];
%   sparsified = sparsify_equal_dims(variantDims, access);
  
%   sparseRect = emptyList(denseSpace.numDims);
%   for(int i  = 0; i < denseSpace.numDims; i++) {
%     if (denseSpace.indices[i] in variantDims) {
%       sparseRect[i] = sparsified.map(i);
%     } else {
%       sparseRect[i] = denseSpace[i];
%     }

%     return IterationSpace(sparseRect, denseSpace.constraints);
%   }
% }
% \end{lstlisting}
% Where \verb.sparsified. holds some map of the iterator name to its position in the variant space.





% \begin{lstlisting}

% using POL=KernelPolicy<
%   statement::For<0,loop_exec,
%     statement::For<1,loop_exec,
%       statement::For<2,loop_exec,
%         statement::For<3,loop_exec,
%           statement::Lambda<0>
%         >
%       >
%     >
%   >
% >;

% auto mttkrp_lam = [&](auto i0, auto i1, auto i2, auto i3) {
%   A(i0,i1) += B(i0,i2,i3) * D(i3,i1) * C(i2,i1);
% };

% auto sparsified = sparsify(dense_segs, B, {0,2,3});
% auto knl = make_sparse_kernel<POL>(sparsified, mttkrp_lam);

% knl();
% \end{lstlisting}



% \section{Implementation}

% \section{Evaluation}

% \section{Discussion}
% \section{Conclusion}